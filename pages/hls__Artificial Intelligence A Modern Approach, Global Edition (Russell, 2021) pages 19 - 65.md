file:: [Artificial Intelligence A Modern Approach, Global Edition (Russell, 2021) pages 19 - 65.pdf](../assets/Artificial Intelligence A Modern Approach, Global Edition (Russell, 2021) pages 19 - 65.pdf)
file-path:: ../assets/Artificial Intelligence A Modern Approach, Global Edition (Russell, 2021) pages 19 - 65.pdf

- Chapter 1 - Introduction
  hl-page:: 1
  ls-type:: annotation
  id:: 67c2612d-5964-4e19-8def-fceb67b6ad0c
  hl-color:: red
	- We call ourselves Homo sapiens—man the wise—because our **intelligence** is so important to us.
	  hl-page:: 1
	  ls-type:: annotation
	  id:: 67c2615c-e9bb-4e59-ad96-6d356b565fd5
	  hl-color:: blue
	  collapsed:: true
		- For thousands of years, we have tried to understand *how we think and act*—that is, how our brain, a mere handful of matter, can perceive, understand, predict, and manipulate a world far larger and more complicated than itself
		  ls-type:: annotation
		  hl-page:: 1
		  hl-color:: yellow
		  id:: 67c26179-f254-46f3-85bf-bfb9b461d929
		- The ﬁeld of **artiﬁcial intelligence**, or AI, is concerned with not just understanding but also building intelligent entities—machines that can compute how to act effectively and safely in a wide variety of novel situations.
		  hl-page:: 1
		  ls-type:: annotation
		  id:: 67c2619e-ea5a-47bd-821f-dd6595aaef1b
		  hl-color:: yellow
	- Surveys regularly rank AI as one of the most interesting and fastest-growing ﬁelds, and it is already generating over a trillion dollars a year in revenue.
	  ls-type:: annotation
	  hl-page:: 1
	  hl-color:: blue
	  id:: 67c261d1-d775-4f1f-a362-9890a1232594
	  collapsed:: true
		- AI expert Kai-Fu Lee predicts that its impact will be “more than anything in the history of mankind.” Moreover, the intellectual frontiers of AI are wide open.
		  ls-type:: annotation
		  hl-page:: 1
		  hl-color:: yellow
		  id:: 67c26256-3bf3-40d0-8071-78558b1f73a9
		- Whereas a student of an older science such as physics might feel that the best ideas have already been discovered by Galileo, Newton, Curie, Einstein, and the rest, AI still has many openings for full-time masterminds.
		  ls-type:: annotation
		  hl-page:: 1
		  hl-color:: yellow
		  id:: 67c26269-3a27-4d28-b8c8-7da1ee0309f3
	- AI currently encompasses a huge variety of subﬁelds, ranging from the general (learning, reasoning, perception, and so on) to the speciﬁc, such as playing chess, proving mathematical theorems, writing poetry, driving a car, or diagnosing diseases. AI is relevant to any intellectual task; it is truly a universal ﬁeld.
	  ls-type:: annotation
	  hl-page:: 1
	  hl-color:: blue
	  id:: 67c26286-8477-4269-aeb4-4dbcca9dd441
	- 1.1 What Is AI?
	  ls-type:: annotation
	  hl-page:: 1
	  hl-color:: red
	  id:: 67c26296-96fc-4439-9734-993ae22073da
	  collapsed:: true
		- We have claimed that AI is interesting, but we have not said what it is.
		  ls-type:: annotation
		  hl-page:: 1
		  hl-color:: blue
		  id:: 67c262a7-990c-46a0-a4bb-25033dcbeb3c
		  collapsed:: true
			- Historically, researchers have pursued several different versions of AI. Some have deﬁned intelligence in terms of ﬁdelity to human performance, while others prefer an abstract, formal deﬁnition of intelligence called:
			  ls-type:: annotation
			  hl-page:: 1
			  hl-color:: yellow
			  id:: 67c262bf-f095-42b5-9c8a-79d49acb81bd
			- **rationality**—loosely speaking, doing the “right thing.” The subject matter Rationality itself also varies: some consider intelligence to be a property of internal thought processes and reasoning, while others focus on intelligent behavior, an external characterization.[^1]
			  hl-page:: 1
			  ls-type:: annotation
			  id:: 67c262d3-01bf-4b76-9d06-6597cdec236b
			  hl-color:: green
				- hl-page:: 1
				  ls-type:: annotation
				  id:: 67c26312-4c02-41c1-83f0-ff8566537c1f
				  hl-color:: purple
				  hl-stamp:: 1740792672097
				  [^1]:In the public eye, there is sometimes confusion between the terms “artiﬁcial intelligence” and “machine learning.” Machine learning is a subﬁeld of AI that studies the ability to improve performance based on experience. Some AI systems use machine learning methods to achieve competence, but some do not.
		- From these two dimensions—human vs. rational[^2] and thought vs. behavior—there are four possible combinations, and there have been adherents and research programs for all four.
		  hl-page:: 1
		  ls-type:: annotation
		  id:: 67c26326-4acd-4bbf-9994-53df7478f6e3
		  hl-color:: blue
		  collapsed:: true
			- The methods used are necessarily different: the pursuit of human-like intelligence must be in part an empirical science related to psychology, involving observations and hypotheses about actual human behavior and thought processes; a rationalist approach, on the other hand, involves a combination of mathematics and engineering, and connects to statistics, control theory, and economics.
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: yellow
			  id:: 67c263c0-7c96-4e43-96c7-46e8bb867556
			- The various groups have both disparaged and helped each other. Let us look at the four approaches in more detail.
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: yellow
			  id:: 67c263c9-0d87-4808-9316-2c8a142879b5
			- hl-page:: 1
			  ls-type:: annotation
			  id:: 67c2635d-e87e-40cb-a72c-869f03713613
			  hl-color:: purple
			  [^2]:We are not suggesting that humans are “irrational” in the dictionary sense of “deprived of normal mental clarity.” We are merely conceding that human decisions are not always mathematically perfect.
		- 1.1.1 Acting humanly: The Turing test approach
		  ls-type:: annotation
		  hl-page:: 2
		  hl-color:: red
		  id:: 67c263f3-a8f6-43d7-beba-a044b66cb059
		  collapsed:: true
			- The **Turing test**, proposed by Alan Turing (1950), was designed as a thought experiment thatTuring test would sidestep the philosophical vagueness of the question “Can a machine think?
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: green
			  id:: 67c26420-84bc-47fe-8bd4-f785cdd57fab
			  collapsed:: true
				- A computer passes the test if a human interrogator, after posing some written questions, cannot tell whether the written responses come from a person or from a computer. Chapter 28 discusses the details of the test and whether a computer would really be intelligent if it passed.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: yellow
				  id:: 67c26442-fbdf-4b83-8cef-a500958fc50e
			- For now, we note that programming a computer to pass a rigorously applied test provides plenty to work on. The computer would need the following capabilities:
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: green
			  id:: 67c26455-35ea-4175-825a-969362e70274
			  hl-stamp:: 1740792925206
			  collapsed:: true
				- **natural language processing** to communicate successfully in a human language;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26479-0d66-44d4-88fa-98c9b3b07fbd
				- **knowledge representation** to store what it knows or hears;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26487-f746-4560-a935-da0c1e69d34e
				- **automated reasoning** to answer questions and to draw new conclusions;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26496-1246-4e34-abe4-f32b4baf880f
				- **machine learning** to adapt to new circumstances and to detect and extrapolate patterns.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c264a6-4ab8-4a2d-8d75-fb9855410bb0
			- Turing viewed the *physical* simulation of a person as unnecessary to demonstrate intelligence.
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: blue
			  id:: 67c265c0-7598-484c-a09d-e95ef32a9043
			- However, other researchers have proposed a **total Turing test**, which requires interaction withTotal Turing test objects and people in the real world. To pass the total Turing test, a robot will need
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: green
			  id:: 67c26605-a21e-4528-9d10-97e7b355c99e
			  collapsed:: true
				- **computer vision** and speech recognition to perceive the world;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c2662a-4721-4dcf-946b-9245814b01cd
				- **robotics** to manipulate objects and move about.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26637-a688-40f8-b256-f0a002272c0a
			- These six disciplines compose most of AI. Yet AI researchers have devoted little effort to passing the Turing test, believing that it is more important to study the underlying principles of intelligence.
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: blue
			  id:: 67c26655-00f4-4a6b-aaa3-0b27d1c07f00
				- The quest for “artiﬁcial ﬂight” succeeded when engineers and inventors stopped imitating birds and started using wind tunnels and learning about aerodynamics.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: yellow
				  id:: 67c266a7-b3f1-4cb8-aeb4-b9a7e7c15778
				- Aeronautical engineering texts do not deﬁne the goal of their ﬁeld as making “machines thatﬂy so exactly like pigeons that they can fool even other pigeons.”
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: yellow
				  id:: 67c266b2-ae44-4312-a990-da62f2f293aa
		- 1.1.2 Thinking humanly: The cognitive modeling approach
		  ls-type:: annotation
		  hl-page:: 2
		  hl-color:: red
		  id:: 67c266d8-ced1-4bab-b2ce-e81ea5be2ab4
		  collapsed:: true
			- To say that a program thinks like a human, we must know how humans think. We can learn about human thought in three ways:
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: blue
			  id:: 67c266ff-343b-44fe-9c11-14e29d7412a2
			  collapsed:: true
				- **introspection**—trying to catch our own thoughts as they go by;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26766-9473-4d7c-adc0-4e62679a9fdb
				- **psychological experiments**—observing a person in action;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26787-9d44-4496-b692-5478b2edfabb
				- **brain imaging**—observing the brain in action.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c267b1-53d9-4746-8900-0db35edc5ab2
			- Once we have a sufﬁciently precise theory of the mind, it becomes possible to express the theory as a computer program.
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: blue
			  id:: 67c267e6-85a1-4dbf-85be-a14d77fe1763
			  collapsed:: true
				- If the program’s input–output behavior matches corresponding human behavior, that is evidence that some of the program’s mechanisms could also be operating in humans.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: yellow
				  id:: 67c26866-0b52-4ad5-89f7-7cf38b4c00c0
			- For example, Allen Newell and Herbert Simon, who developed GPS, the “General Problem Solver” (Newell and Simon, 1961), were not content merely to have their program solve problems correctly.
			  hl-page:: 2
			  ls-type:: annotation
			  id:: 67c26879-c7b1-4c94-80fa-b27e99e48639
			  hl-color:: blue
			  collapsed:: true
				- They were more concerned with comparing the sequence and timing of its reasoning steps to those of human subjects solving the same problems
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c26891-23ee-49da-b967-343fb56d15fb
			- The interdisciplinary ﬁeld of **cognitive science** brings together computer models from AI and experimental techniques from psychology to construct precise and testable theories of the human mind.
			  hl-page:: 3
			  ls-type:: annotation
			  id:: 67c2689e-d4cd-4f25-9875-6544f9853478
			  hl-color:: green
			- Cognitive science is a fascinating ﬁeld in itself, worthy of several textbooks and at least one encyclopedia (Wilson and Keil, 1999).
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: blue
			  id:: 67c268ea-b5a3-4549-932e-6018bacdcbee
			  collapsed:: true
				- We will occasionally comment on similarities or differences between AI techniques and human cognition. 
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c268fb-a870-4087-b370-ca59c4a42d99
				- Real cognitive science, however, is necessarily based on experimental investigation of actual humans or animals. We will leave that for other books, as we assume the reader has only a computer for experimentation.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c26917-35aa-4a2e-85ca-cfaab0f95a36
			- In the early days of AI there was often confusion between the approaches. An author would argue that an algorithm performs well on a task and that it is *therefore* a good model of human performance, or vice versa.
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: blue
			  id:: 67c26948-19ce-4d42-b3eb-6a378eaf2e78
				- Modern authors separate the two kinds of claims; this distinction has allowed both AI and cognitive science to develop more rapidly.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c2695f-054a-4c70-98b4-a19404ddfa7e
				- The two ﬁelds fertilize each other, most notably in computer vision, which incorporates neurophysiological evidence into computational models.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c269b3-9df8-4ac6-acbf-735a2f8d831f
				- Recently, the combination of neuroimaging methods combined with machine learning techniques for analyzing such data has led to the beginnings of a capability to “read minds”—that is, to ascertain the semantic content of a person’s inner thoughts. This capability could, in turn, shed further light on how human cognition works.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c269d0-3ff3-493d-a979-bdbe28577808
		- 1.1.3 Thinking rationally: The “laws of thought” approach
		  ls-type:: annotation
		  hl-page:: 3
		  hl-color:: red
		  id:: 67c269e1-d009-4476-8221-3bda36c35de6
		  collapsed:: true
			- The Greek philosopher Aristotle was one of the ﬁrst to attempt to codify “right thinking”— that is, irrefutable reasoning processes.
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: blue
			  id:: 67c269fb-1070-4a2b-99a8-57a3d89a5692
			  collapsed:: true
				- His **syllogisms** provided patterns for argument structures that always yielded correct conclusions when given correct premises
				  hl-page:: 3
				  ls-type:: annotation
				  id:: 67c26aab-fda6-4598-a320-645752cc7159
				  hl-color:: green
				  collapsed:: true
					- The canonical example starts with *Socrates is a man and all men are mortal* and concludes that *Socrates is mortal*. (This example is probably due to Sextus Empiricus rather than Aristotle.)
					  hl-page:: 3
					  ls-type:: annotation
					  id:: 67c26ad5-d8c3-4ef4-a951-0cac349d0f97
					  hl-color:: yellow
				- These laws of thought were supposed to govern the operation of the mind; their study initiated the ﬁeld called **logic**.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: green
				  id:: 67c26af5-3a3f-4b10-94d8-fbd0fcb9f563
			- Logicians in the 19th century developed a precise notation for statements about objects in the world and the relations among them. (Contrast this with ordinary arithmetic notation, which provides only for statements about numbers.)
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: blue
			  id:: 67c26b29-0618-49f2-ae3f-03b41b27b506
			  collapsed:: true
				- By 1965, programs could, in principle, solve any solvable problem described in logical notation.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c26b63-f99e-4e63-b36d-e3c6d549b801
			- The so-called **logicist** tradition within artiﬁcial intelligence hopes to build on such programs to create intelligent systems.
			  hl-stamp:: 1740794738709
			  hl-page:: 3
			  ls-type:: annotation
			  id:: 67c26b70-9cd4-4d35-9f50-e20937dcf2ad
			  hl-color:: green
			- Logic as conventionally understood requires knowledge of the world that is *certain*—a condition that, in reality, is seldom achieved.
			  hl-page:: 3
			  ls-type:: annotation
			  id:: 67c26b95-0de2-4224-9103-cb708e02cf02
			  hl-color:: blue
			  collapsed:: true
				- We simply don’t know the rules of, say, politics or warfare in the same way that we know the rules of chess or arithmetic.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c26bcd-e776-4650-901d-b8def33d9637
			- The theory of **probability** ﬁlls this gap, allowing rigorous reasoning with uncertain information.
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: green
			  id:: 67c26bdb-b644-44dd-abf9-44a33075135e
			  collapsed:: true
				- In principle, it allows the construction of a comprehensive model of rational thought, leading from raw perceptual information to an understanding of how the world works to predictions about the future.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c26d4a-7032-49ab-a4be-c5b9a3ea6839
			- What it does not do, is generate intelligent *behavior*. For that, we need a theory of rational action. Rational thought, by itself, is not enough.
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: blue
			  id:: 67c26d68-947b-412d-862a-330144043dfb
			  hl-stamp:: 1740795249341
		- 1.1.4 Acting rationally: The rational agent approach
		  ls-type:: annotation
		  hl-page:: 3
		  hl-color:: red
		  id:: 67c26d84-25e1-46f6-9e0c-3f1b013544fb
		  collapsed:: true
			- An **agent** is just something that acts (agent comes from the Latin agere, to do).
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: green
			  id:: 67c26db2-377e-4f0c-a356-4b8210946856
			  collapsed:: true
				- Of course, all computer programs do something, but computer agents are expected to do more: operate autonomously, perceive their environment, persist over a prolonged time period, adapt to change, and create and pursue goals.
				  hl-page:: 4
				  ls-type:: annotation
				  id:: 67c26dd3-465e-4abf-88fa-c1e516ee984c
				  hl-color:: yellow
			- A **rational agent** is one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome.
			  hl-page:: 4
			  ls-type:: annotation
			  id:: 67c26de3-4928-49d4-b8d0-4cef1f5da99a
			  hl-color:: green
			- In the “laws of thought” approach to AI, the emphasis was on correct inferences.
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c26e27-c78d-409f-9b84-7718655ed78e
			  collapsed:: true
				- Making correct inferences is sometimes *part* of being a rational agent, because one way to act rationally is to deduce that a given action is best and then to act on that conclusion.
				  hl-page:: 4
				  ls-type:: annotation
				  id:: 67c279f5-562e-4b0f-821d-dc50ca572dd9
				  hl-color:: yellow
				- On the other hand, there are ways of acting rationally that cannot be said to involve inference. For example, recoiling from a hot stove is a reﬂex action that is usually more successful than a slower action taken after careful deliberation.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27a1c-773d-4333-ab58-5eddb23b5746
			- All the skills needed for the Turing test also allow an agent to act rationally.
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c27a3a-531f-4e50-9f8a-d52b61552a5e
			  collapsed:: true
				- Knowledge representation and reasoning enable agents to reach good decisions.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27a8e-7097-4d7c-8bf9-aaa1c6db3492
				- We need to be able to generate comprehensible sentences in natural language to get by in a complex society.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27a9a-be71-43d8-bd66-6ffc66ac5863
				- We need learning not only for erudition, but also because it improves our ability to generate effective behavior, especially in circumstances that are new.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27aa6-a46c-445a-b96b-fb445310f851
			- The rational-agent approach to AI has two advantages over the other approaches.
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c27aca-1ff2-48d2-ac1f-8e46f9b2f324
			  collapsed:: true
				- **First**, it is more general than the “laws of thought” approach because correct inference is just one of several possible mechanisms for achieving rationality.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27aeb-8a17-4102-88ee-b4f46f7b5375
				- Second, it is more amenable to scientiﬁc development. The standard of rationality is mathematically well deﬁned and completely general.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27b14-242b-4308-b116-57f8e215299c
					- ==_However it does create duplicitous answers that lack a cohesive outcome, it is therefore fractuous. This lack of directionality and discipline towards a perceived goal, reduces certainty of action that is core to having agency. A rational agent is by definition, not an agent, but constructs the environment of potentiality. The agent must collapse the possible into the certainty of outcome based on the desirable objective. Agent as defined here exposes the agent of Chaos as it fails to act and therefore fails to exclude an infinitely large scope of undesirable outcome._==
				- We can often work back from this speciﬁcation to derive agent designs that provably achieve it—something that is largely impossible if the goal is to imitate human behavior or thought processes.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27bd6-9bc3-42b1-8330-9b5d45e3dbad
			- For these reasons, the rational-agent approach to AI has prevailed throughout most of the ﬁeld’s history.
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c28e06-1f8a-4e61-b266-fdd43e6b4402
			  collapsed:: true
				- In the early decades, rational agents were built on logical foundations and formed deﬁnite plans to achieve speciﬁc goals.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c28e35-bfa2-48ab-90ee-f3a9476d1c91
				- Later, methods based on probability theory and machine learning allowed the creation of agents that could make decisions under uncertainty to attain the best expected outcome.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c28e46-3f56-4941-b271-3dbfe4889f10
				- __In a nutshell, AI has focused on the study and construction of agents that *do the right thing*__. What counts as the right thing is deﬁned by the objective that we provide to the agent.
				  hl-page:: 4
				  ls-type:: annotation
				  id:: 67c28e54-6a53-411d-a139-9a9fceb9d641
				  hl-color:: yellow
				- This general paradigm is so pervasive that we might call it the **standard model.** It prevails not only in AI, but also in control theory, where a controller minimizes a cost function; in operations research, where a policy maximizes a sum of rewards; in statistics, where a decision rule minimizes a loss function; and in economics, where a decision maker maximizes utility or some measure of social welfare.
				  hl-page:: 4
				  ls-type:: annotation
				  id:: 67c28ef0-5048-4f82-981d-32729c61d73b
				  hl-color:: yellow
			- We need to make one important reﬁnement to the standard model to account for the fact that perfect rationality—always taking the exactly optimal action—is not feasible in complex environments. The computational demands are just too high. 
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c2f3a2-0a0e-45d1-bef1-0e48d9ec08a9
			- Chapters 6 and 16 deal with the issue of **limited rationality**—acting appropriately when there is not enough time to do all the computations one might like. However, perfect rationality often remains a good starting point for theoretical analysis.
			  hl-stamp:: 1740829625338
			  hl-page:: 4
			  ls-type:: annotation
			  id:: 67c2f3b5-c33a-448b-8a03-43881650d963
			  hl-color:: green
		- 1.1.5 Beneﬁcial machines
		  ls-type:: annotation
		  hl-page:: 4
		  hl-color:: red
		  id:: 67c2f3df-228a-4430-927f-661b676c4437
		  collapsed:: true
			- The standard model has been a useful guide for AI research since its inception, but it is probably not the right model in the long run. 
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c2f3f0-6e05-422c-ae7e-081df0c5157a
			  collapsed:: true
				- The reason is that the standard model assumes that we will supply a fully speciﬁed objective to the machine.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c2f3f6-e55e-412e-9943-a0b0e49a7c0f
			- For an artiﬁcially deﬁned task such as chess or shortest-path computation, the task comes with an objective built in—so the standard model is applicable
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c2f40b-f0a5-4783-adec-2bcd464b565c
			  collapsed:: true
				- As we move into the real world, however, it becomes more and more difﬁcult to specify the objective completely and correctly.
				  hl-page:: 4
				  ls-type:: annotation
				  id:: 67c2f420-23fd-40f5-9574-3f44f5eafa80
				  hl-color:: yellow
				- For example, in designing a self-driving car, one might think that the objective is to reach the destination safely. But driving along any road incurs a risk of injury due to other errant drivers, equipment failure, and so on; thus, a strict goal of safety requires staying in the garage.
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b2c5-1c34-4615-a695-c454fe0c712b
				- There is a tradeoff between making progress towards the destination and incurring a risk of injury. How should this tradeoff be made? Furthermore, to what extent can we allow the car to take actions that would annoy other drivers? How much should the car moderate its acceleration, steering, and braking to avoid shaking up the passenger?
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b301-207e-4b81-bc6f-3d85be2e1e77
				- These kinds of questions are difﬁcult to answer a priori. They are particularly problematic in the general area of human–robot interaction, of which the self-driving car is one example.
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b309-e960-422f-a374-018af5fbd194
			- The problem of achieving agreement between our true preferences and the objective we put into the machine is called the:
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: blue
			  id:: 67c3b31c-f086-450b-9575-56b4f3095f1d
			- **value alignment problem** - the values or objectives put into the machine must be aligned with those of the human
			  hl-page:: 5
			  ls-type:: annotation
			  id:: 67c3b33c-462f-4a4f-9e31-c874165f47e8
			  hl-color:: green
			  collapsed:: true
				- If we are developing an AI system in the lab or in a simulator—as has been the case for most of the ﬁeld’s history—there is an easyﬁx for an incorrectly speciﬁed objective: reset the system, ﬁx the objective, and try again.
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b38a-5301-4a14-a970-6de39e2b6271
				- As the ﬁeld progresses towards increasingly capable intelligent systems that are deployed in the real world, this approach is no longer viable. A system deployed with an incorrect objective will have negative consequences. Moreover, the more intelligent the system, the more negative the consequences.
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b3a7-a327-4889-871e-f7847144a14e
			- Returning to the apparently unproblematic example of chess, consider what happens if the machine is intelligent enough to reason and act beyond the conﬁnes of the chessboard.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: blue
			  id:: 67c3b3bf-8abc-458b-9839-0713f1c2a080
			  collapsed:: true
				- In that case, it might attempt to increase its chances of winning by such ruses as hypnotizing or blackmailing its opponent or bribing the audience to make rustling noises during its opponent’s thinking time.[^3]
				  hl-page:: 5
				  ls-type:: annotation
				  id:: 67c3b3ce-ffe7-4e97-bd27-d89e301d967e
				  hl-color:: yellow
				  collapsed:: true
					- hl-page:: 5
					  ls-type:: annotation
					  id:: 67c3b3da-d4da-4fff-8cd8-a566c775d33a
					  hl-color:: purple
					  [^3]:In one of the ﬁrst books on chess, Ruy Lopez (1561) wrote, “Always place the board so the sun is in your opponent’s eyes.”
				- It might also attempt to hijack additional computing power for itself. *These behaviors are not “unintelligent” or “insane”; they are a logical consequence of deﬁning winning as the sole objective for the machine*.
				  hl-page:: 5
				  ls-type:: annotation
				  id:: 67c3b414-dc5f-4bce-8460-d52aab715d71
				  hl-color:: yellow
			- It is impossible to anticipate all the ways in which a machine pursuing a ﬁxed objective might misbehave. There is good reason, then, to think that the standard model is inadequate.
			  hl-page:: 5
			  ls-type:: annotation
			  id:: 67c3b587-f8c0-478a-989d-22064c5087af
			  hl-color:: blue
			  collapsed:: true
				- We don’t want machines that are intelligent in the sense of pursuing *their* objectives; we want them to pursue *our* objectives. If we cannot transfer those objectives perfectly to the machine, then we need a new formulation—one in which the machine is pursuing our objectives, but is necessarily *uncertain* as to what they are.
				  hl-page:: 5
				  ls-type:: annotation
				  id:: 67c3b5c0-362f-454f-a548-5ae0abc82401
				  hl-color:: yellow
				- When a machine knows that it doesn’t know the complete objective, it has an incentive to act cautiously, to ask permission, to learn more about our preferences through observation, and to defer to human control.
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b624-03d2-4c5f-a824-072afd8d503f
			- Ultimately, we want agents that are **provably beneﬁcial** to humans. We will return to this topic in Section 1.5.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: green
			  id:: 67c3b631-2d83-405e-993f-a37dfaf8713b
			  hl-stamp:: 1740879411869
- 1.2 The Foundations of Artiﬁcial Intelligence
  ls-type:: annotation
  hl-page:: 5
  hl-color:: red
  id:: 67c3b65f-aee2-4c0e-87d3-1e55824895bf
	- In this section, we provide a brief history of the disciplines that contributed ideas, viewpoints, and techniques to AI.
	  ls-type:: annotation
	  hl-page:: 5
	  hl-color:: blue
	  id:: 67c3b678-030c-4a4f-99b3-f82557c3e90b
	  collapsed:: true
		- Like any history, this one concentrates on a small number of people, events, and ideas and ignores others that also were important.
		  ls-type:: annotation
		  hl-page:: 5
		  hl-color:: yellow
		  id:: 67c3b693-a559-4ff0-8d08-c137059ed341
		- We organize the history around a series of questions. We certainly would not wish to give the impression that these questions are the only ones the disciplines address or that the disciplines have all been working toward AI as their ultimate fruition.
		  ls-type:: annotation
		  hl-page:: 5
		  hl-color:: yellow
		  id:: 67c3b6b3-19f7-4d4d-afa1-0d49e8fec927
	- 1.2.1 Philosophy
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: red
	  id:: 67c3b6c1-3fdd-4671-a8ca-8cd2f9e2a1b6
	  collapsed:: true
		- [[Aristotle]] (384–322 BCE) was the ﬁrst to formulate a precise set of laws governing the rational part of the mind.
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: blue
		  id:: 67c3b6d5-e144-4e8d-9b9f-309bdc11f62b
		  collapsed:: true
			- He developed an informal system of syllogisms for proper reasoning, which in principle allowed one to generate conclusions mechanically, given initial premises.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: yellow
			  id:: 67c3b754-4918-478f-bc97-69501ef15ff6
		- [[Ramon Llull]] (c. 1232–1315) devised a system of reasoning published as *Ars Magna* or *The Great Art* (1305). Llull tried to implement his system using an actual mechanical device: a set of paper wheels that could be rotated into different permutations.
		  hl-page:: 6
		  ls-type:: annotation
		  id:: 67c3b76f-6850-43be-ad0b-675e3f590861
		  hl-color:: blue
		- Around 1500, [[Leonardo da Vinci]] (1452–1519) designed but did not build a mechanical calculator; recent reconstructions have shown the design to be functional
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: blue
		  id:: 67c3b7e2-91f1-4ffa-8b88-186776edb478
		- The ﬁrst known calculating machine was constructed around 1623 by the German scientist [[Wilhelm Schickard]] (1592–1635).
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: blue
		  id:: 67c3b7ff-185f-4fbb-afd0-451181dbf59e
		  hl-stamp:: 1740880466711
		- [[Blaise Pascal]] (1623–1662) built the Pascaline in 1642 and wrote that it “produces effects which appear nearer to thought than all the actions of animals.
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: blue
		  id:: 67c3b81a-92ff-4532-a94c-8dae08e89e36
		  hl-stamp:: 1740880485715
		- [[Gottfried Wilhelm Leibniz]] (1646–1716) built a mechanical device intended to carry out operations on concepts rather than numbers, but its scope was rather limited
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: blue
		  id:: 67c3b840-f7bc-4801-ad95-5707edb0b1b4
		  hl-stamp:: 1740880491153
		- In his 1651 book *Leviathan*, [[Thomas Hobbes]] (1588–1679) suggested the idea of a thinking machine, an “artiﬁcial animal” in his words, arguing “For what is the heart but a spring; and the nerves, but so many strings; and the joints, but so many wheels.” He also suggested that reasoning was like numerical computation: “For ‘reason’ . . . is nothing but ‘reckoning,’ that is adding and subtracting.”
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: blue
		  id:: 67c3b888-7a47-4c37-8261-c93773965cbe
		  hl-stamp:: 1740880495585
		- It’s one thing to say that the mind operates, at least in part, according to logical or numerical rules, and to build physical systems that emulate some of those rules. It’s another to say that the mind itself is such a physical system.
		  hl-page:: 6
		  ls-type:: annotation
		  id:: 67c3b8c7-19b9-4abc-8114-0aca63b2eb28
		  hl-color:: blue
		  hl-stamp:: 1740880089028
		- [[René Descartes]] (1596–1650) gave the ﬁrst clear discussion of the distinction between mind and matter. He noted that a purely physical conception of the mind seems to leave little room for free will.
		  hl-page:: 6
		  ls-type:: annotation
		  id:: 67c3b8fa-ffd4-48d1-aef2-4f8faf8965f4
		  hl-color:: blue
		  hl-stamp:: 1740880460455
		  collapsed:: true
			- If the mind is governed entirely by physical laws, then it has no more free will than a rock “deciding” to fall downward.
			  ls-type:: annotation
			  hl-page:: 6
			  hl-color:: yellow
			  id:: 67c3ba26-f8da-499a-b44a-6894bd5a6d51
		- Descartes was a proponent of **dualism**. He held that there is a part of the human mind (orDualism soul or spirit) that is outside of nature, exempt from physical laws. Animals, on the other hand, did not possess this dual quality; they could be treated as machines.
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: green
		  id:: 67c3ba3c-4618-4150-b496-6be028cd638c
		- An alternative to dualism is **materialism**, which holds that the brain’s operation according to the laws of physics constitutes the mind. Free will is simply the way that the perception of available choices appears to the choosing entity.
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: green
		  id:: 67c3bb18-2f72-46d0-adf2-39a407753929
		  hl-stamp:: 1740880679166
		- The terms **physicalism** and **naturalism** are also used to describe this view that stands in contrast to the supernatural.
		  hl-page:: 6
		  ls-type:: annotation
		  id:: 67c3bb2f-5f4c-4060-9711-45fa920faaa3
		  hl-color:: green
		- Given a physical mind that manipulates knowledge, the next problem is to establish the source of knowledge.
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: blue
		  id:: 67c3bb52-a6e1-49e9-ac87-d198900e6c7c
		- The **empiricism** movement, starting with [[Francis Bacon]]’s (1561–1626) *Novum Organum*,[^4] is characterized by a dictum of [[John Locke]] (1632–1704): “Nothing is in the understanding, which was not ﬁrst in the senses.”
		  hl-page:: 6
		  ls-type:: annotation
		  id:: 67c3bb60-ea56-45c5-b2af-5d2109b271ab
		  hl-color:: green
		  collapsed:: true
			- hl-page:: 6
			  ls-type:: annotation
			  id:: 67c3bbb0-0b43-4cbb-ad99-3f1a90c4c582
			  hl-color:: purple
			  [^4]:The *Novum Organum* is an update of Aristotle’s *Organon*, or instrument of thought.
		- [[David Hume]]’s (1711–1776) *A Treatise of Human Nature* (Hume, 1739) proposed what is now known as the principle of **induction**: that general rules are acquired by exposure toInduction repeated associations between their elements.
		  hl-page:: 6
		  ls-type:: annotation
		  id:: 67c3bfa8-92f4-4970-b441-d028aa7cc719
		  hl-color:: green
		- Building on the work of [[Ludwig Wittgenstein]] (1889–1951) and [[Bertrand Russell]] (1872–1970), the famous [[Vienna Circle]] (Sigmund, 2017), a group of philosophers and mathematicians meeting in Vienna in the 1920s and 1930s, developed the doctrine of **logical positivism**.
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: green
		  id:: 67c3bfef-8197-4675-a928-65b2ed904a0d
		- This doctrine holds that all knowledge can be characterized by logical theories connected, ultimately, to **observation sentences** that correspond to sensory inputs; thus logical positivism combines rationalism and empiricism.
		  hl-page:: 7
		  ls-type:: annotation
		  id:: 67c3c02b-33a0-4b0c-87ee-b76cbe9beafb
		  hl-color:: green
		  hl-stamp:: 1740882066321
		- The **conﬁrmation theory** of [[Rudolf Carnap]] (1891–1970) and [[Carl Hempel]] (1905–1997) attempted to analyze the acquisition of knowledge from experience by quantifying the degree of belief that should be assigned to logical sentences based on their connection to observations that conﬁrm or disconﬁrm them.
		  hl-page:: 7
		  ls-type:: annotation
		  id:: 67c3c0a6-147a-4b9e-8596-46f1c79332c0
		  hl-color:: green
		  collapsed:: true
			- Carnap’s book *The Logical Structure of the World* (1928) was perhaps the ﬁrst theory of mind as a computational process.
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: yellow
			  id:: 67c3c0c6-6d7f-40e2-a21f-24a686c4542a
		- The ﬁnal element in the philosophical picture of the mind is the connection between knowledge and action.
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: blue
		  id:: 67c3c0e4-4b01-4887-a23d-502d7a781551
		  collapsed:: true
			- This question is vital to AI because intelligence requires action as well as reasoning. Moreover, only by understanding how actions are justiﬁed can we understand how to build an agent whose actions are justiﬁable (or rational).
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: yellow
			  id:: 67c3c0ee-3acd-4afe-bd23-94a06eb9cd77
		- Aristotle argued (in *De Motu Animalium*) that actions are justiﬁed by a logical connection between goals and knowledge of the action’s outcome:
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: blue
		  id:: 67c3c106-0527-47f2-baf3-15e7b4d42b63
		  collapsed:: true
			- ls-type:: annotation
			  hl-page:: 7
			  hl-color:: yellow
			  id:: 67c3c27c-0022-40c1-87bc-d9359f6d0edf
			  >But how does it happen that thinking is sometimes accompanied by action and sometimes not, sometimes by motion, and sometimes not? It looks as if almost the same thing happens as in the case of reasoning and making inferences about unchanging objects. But in that case the end is a speculative proposition . . . whereas here the conclusion which results from the two premises is an action. . . . I need covering; a cloak is a covering. I need a cloak. What I need, I have to make; I need a cloak. I have to make a cloak. And the conclusion, the “I have to make a cloak,” is an action.
		- In the *Nicomachean Ethics* (Book III. 3, 1112b), Aristotle further elaborates on this topic, suggesting an algorithm:
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: blue
		  id:: 67c3c2c3-19e9-4369-bb6e-dda74e78b840
		  collapsed:: true
			- hl-page:: 7
			  ls-type:: annotation
			  id:: 67c3c2d6-da7f-4993-86de-6a87416a6ccf
			  hl-color:: yellow
			  >We deliberate not about ends, but about means. For a doctor does not deliberate whether he shall heal, nor an orator whether he shall persuade, . . . They assume the end and consider how and by what means it is attained, and if it seems easily and best produced thereby; while if it is achieved by one means only they consider *how* it will be achieved by this and by what means *this* will be achieved, till they come to the ﬁrst cause, . . . and what is last in the order of analysis seems to be ﬁrst in the order of becoming. And if we come on an impossibility, we give up the search, e.g., if we need money and this cannot be got; but if a thing appears possible we try to do it.
		- [[Aristotle]]’s algorithm was implemented 2300 years later by Newell and Simon in their **General Problem Solver** program.
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: green
		  id:: 67c3c5f6-8ef5-4593-9b8e-b3f747729146
		  collapsed:: true
			- We would now call it a greedy regression planning system(see Chapter 11). Methods based on logical planning to achieve deﬁnite goals dominated theﬁrst few decades of theoretical research in AI.
			  ls-type:: annotation
			  hl-page:: 7
			  hl-color:: yellow
			  id:: 67c3c61f-10bf-4dbc-82aa-179207267a88
		- Thinking purely in terms of actions achieving goals is often useful but sometimes inapplicable.
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: blue
		  id:: 67c3db63-7d27-49b3-a20f-83907722315d
		  collapsed:: true
			- For example, if there are several different ways to achieve a goal, there needs to be some way to choose among them. More importantly, it may not be possible to achieve a goal with certainty, but some action must still be taken. How then should one decide?
			  hl-page:: 7
			  ls-type:: annotation
			  id:: 67c3dbdd-f24b-4150-950a-dd8840ce47a4
			  hl-color:: yellow
		- [[Antoine Arnauld]] (1662), analyzing the notion of rational decisions in gambling, proposed a quantitative formula for maximizing the expected monetary value of the outcome
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: blue
		  id:: 67c3dc5b-600c-40db-803b-f54174900438
		- Later, [[Daniel Bernoulli]] (1738) introduced the more general notion of **utility** to capture the internal, subjective value of an outcome.
		  hl-page:: 7
		  ls-type:: annotation
		  id:: 67c3dc72-5201-4c31-9056-d08556979214
		  hl-color:: green
		  collapsed:: true
			- The modern notion of rational decision making under uncertainty involves maximizing expected utility, as explained in Chapter 15.
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: yellow
			  id:: 67c3dc99-ad94-4ca5-b14b-b9f897fe7dfa
		- In matters of ethics and public policy, a decision maker must consider the interests of multiple individuals. 
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: blue
		  id:: 67c3dcb9-6f16-481f-8afb-129e09505cf6
		- [[Jeremy Bentham]] (1823) and [[John Stuart Mill]] (1863) promoted the idea of **utilitarianism**: that rational decision making based on maximizing utility should apply to all spheres of human activity, including public policy decisions made on behalf of many individuals.
		  hl-page:: 8
		  ls-type:: annotation
		  id:: 67c3dcd6-d54a-4c56-b2fb-cc7890ef3e71
		  hl-color:: green
		- Utilitarianism is a speciﬁc kind of **consequentialism**: the idea that what is right and wrong is determined by the expected outcomes of an action.
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: green
		  id:: 67c3dd21-8cee-4e8c-a083-c92d75b7137e
		- In contrast, [[Immanuel Kant]], in 1785, proposed a theory of rule-based or **deontological ethics**, in which “doing the right thing” is determined not by outcomes but by universal social laws that govern allowable actions, such as “don’t lie” or “don’t kill.”
		  hl-page:: 8
		  ls-type:: annotation
		  id:: 67c3dd40-5f73-4a22-a7be-9155021905db
		  hl-color:: green
		  collapsed:: true
			- Thus, a utilitarian could tell a white lie if the expected good outweighs the bad, but a Kantian would be bound not to, because lying is inherently wrong.
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: yellow
			  id:: 67c3dd88-92f2-4035-bcd5-a2f04f292482
			- Mill acknowledged the value of rules, but understood them as efﬁcient decision procedures compiled from ﬁrst-principles reasoning about consequences. Many modern AI systems adopt exactly this approach.
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: yellow
			  id:: 67c3dda4-e2e5-4de7-9b5e-28396952b57c
	- 1.2.2 Mathematics
	  ls-type:: annotation
	  hl-page:: 8
	  hl-color:: red
	  id:: 67c3ddb4-e43e-49b7-a0fe-8f23a90f5afd
	  collapsed:: true
		- Philosophers staked out some of the fundamental ideas of AI, but the leap to a formal science required the mathematization of logic and probability and the introduction of a new branch of mathematics: computation.
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: blue
		  id:: 67c3de63-a1c6-4724-80c6-4ccf5a899968
		- The idea of **formal logic** can be traced back to the philosophers of ancient Greece, India, and China, but its mathematical development really began with the work of [[George Boole]] (1815–1864), who worked out the details of propositional, or Boolean, logic (Boole, 1847).
		  hl-page:: 8
		  ls-type:: annotation
		  id:: 67c3de87-d37c-4443-9c58-82c58c41dbab
		  hl-color:: green
		- In 1879, [[Gottlob Frege]] (1848–1925) extended Boole’s logic to include objects and relations, creating the ﬁrst-order logic that is used today.[^5]
		  hl-page:: 8
		  ls-type:: annotation
		  id:: 67c3dedc-3265-4c66-85b7-ede4899ab774
		  hl-color:: blue
		  hl-stamp:: 1740889859943
		  collapsed:: true
			- In addition to its central role in the early period of AI research, ﬁrst-order logic motivated the work of G¨odel and Turing that underpinned computation itself, as we explain below.
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: yellow
			  id:: 67c3df64-49cf-4557-9cdb-7284b832c1d0
			- hl-page:: 8
			  ls-type:: annotation
			  id:: 67c3deed-8775-449b-be58-2478d86c621e
			  hl-color:: purple
			  [^5]:Frege’s proposed notation for ﬁrst-order logic—an arcane combination of textual and geometric features— never became popular.
		- The theory of **probability** can be seen as generalizing logic to situations with uncertainProbability information—a consideration of great importance for AI.
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: green
		  id:: 67c3df9b-d66b-458b-b313-d29c9baca24b
		- [[Gerolamo Cardano]] (1501–1576) ﬁrst framed the idea of probability, describing it in terms of the possible outcomes of gambling events.
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: blue
		  id:: 67c3faf6-879d-4fae-8f6e-5d059e76228f
		- In 1654, [[Blaise Pascal]] (1623–1662), in a letter to [[Pierre Fermat]] (1601–1665), showed how to predict the future of an unﬁnished gambling game and assign average payoffs to the gamblers.
		  hl-page:: 8
		  ls-type:: annotation
		  id:: 67c3fb14-d264-49dc-8a35-1d3ce53637b9
		  hl-color:: blue
		  collapsed:: true
			- Probability quickly became an invaluable part of the quantitative sciences, helping to deal with uncertain measurements and incomplete theories
			  ls-type:: annotation
			  hl-page:: 8
			  hl-color:: yellow
			  id:: 67c3fb2c-ac24-4b7d-bae9-71864b2ddf17
		- [[Jacob Bernoulli]] (1654–1705, uncle of Daniel), [[Pierre Laplace]] (1749–1827), and others advanced the theory and introduced new statistical methods.
		  hl-page:: 8
		  ls-type:: annotation
		  id:: 67c3fb40-ba99-48e1-b10b-98fb304587c3
		  hl-color:: blue
		- [[Thomas Bayes]] (1702–1761) proposed a rule for updating probabilities in the light of new evidence; Bayes’ rule is a crucial tool for AI systems.
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: blue
		  id:: 67c3fb61-442b-48b0-892f-ad6889c0ae9b
		- The formalization of probability, combined with the availability of data, led to the emergence of **statistics** as a ﬁeld.
		  ls-type:: annotation
		  hl-page:: 8
		  hl-color:: green
		  id:: 67c3fb76-d64e-4a0b-840c-00971e483897
		  hl-stamp:: 1740897146790
		- One of the ﬁrst uses was [[John Graunt]]’s analysis of London census data in 1662.
		  hl-page:: 8
		  ls-type:: annotation
		  id:: 67c3fb92-aefb-45e1-aa6d-190505479087
		  hl-color:: blue
		- [[Ronald Fisher]] is considered the ﬁrst modern statistician (Fisher,1922).
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: blue
		  id:: 67c3fbc7-4299-4bb6-9e33-4e2de590a486
		  collapsed:: true
			- He brought together the ideas of probability, experiment design, analysis of data, and computing—in 1919, he insisted that he couldn’t do his work without a mechanical calculator called the MILLIONAIRE (the ﬁrst calculator that could do multiplication), even though the cost of the calculator was more than his annual salary (Ross, 2012).
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67c3fbdf-497c-4c66-a4b2-6884c3fb050f
		- The history of computation is as old as the history of numbers, but the ﬁrst nontrivial algorithm is thought to be Euclid’s **algorithm** for computing greatest common divisors.
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: green
		  id:: 67c3fbf3-2240-443b-ab30-871e8c1292a9
		- The word algorithm comes from [[Muhammad ibn Musa al-Khwarizmi]], a 9th century mathematician, whose writings also introduced Arabic numerals and algebra to Europe.
		  hl-page:: 9
		  ls-type:: annotation
		  id:: 67c3fc0b-de53-4270-95d6-670f188d4e3f
		  hl-color:: blue
		  collapsed:: true
			- Boole and others discussed algorithms for logical deduction, and, by the late 19th century, efforts were under way to formalize general mathematical reasoning as logical deduction.
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67c3fc21-1be3-4ab2-930c-776c4d4cf583
		- [[Kurt Gödel]] (1906–1978) showed that there exists an effective procedure to prove any true statement in the ﬁrst-order logic of Frege and Russell, but that ﬁrst-order logic could not capture the principle of mathematical induction needed to characterize the natural numbers. In1931, Gödel showed that limits on deduction do exist.
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: blue
		  id:: 67c3fca2-987a-435a-8ca7-e6812e2b9551
		  hl-stamp:: 1740897480720
		- His **incompleteness theorem** showed that in any formal theory as strong as Peano arithmetic (the elementary theory of natural numbers), there are necessarily true statements that have no proof within the theory.
		  hl-page:: 9
		  ls-type:: annotation
		  id:: 67c3fce7-bc9e-4202-862d-4da832751bd6
		  hl-color:: green
		- This fundamental result can also be interpreted as showing that some functions on the integers cannot be represented by an algorithm—that is, they cannot be computed.
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: blue
		  id:: 67c3fd17-fc44-494a-9060-9825dd997c6a
		- This motivated [[Alan Turing]] (1912–1954) to try to characterize exactly which functions are **computable**—capable of being computed by an effective procedure.
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: green
		  id:: 67c400e1-2f9a-4e50-b2b2-b354b1f98722
		  collapsed:: true
			- The Church–Turing thesis proposes to identify the general notion of computability with functions computed by a Turing machine (Turing, 1936). Turing also showed that there were some functions that no Turing machine can compute. 
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67c4011b-b9a7-4d67-8ea1-1328d5c90a02
			- For example, no machine can tell *in general* whether a given program will return an answer on a given input or run forever.
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67c40125-8104-414b-b666-5964fdea2155
		- Although computability is important to an understanding of computation, the notion of **tractability** has had an even greater impact on AI.
		  ls-type:: annotation
		  hl-page:: 9
		  hl-color:: green
		  id:: 67c40155-883b-4e94-a2ba-8dced243d3a3
		  collapsed:: true
			- Roughly speaking, a problem is called intractable if the time required to solve instances of the problem grows exponentially with the size of the instances.
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67c4016e-7828-4241-baae-960ae44c34e8
			- The distinction between polynomial and exponential growth in complexity was ﬁrst emphasized in the mid-1960s (Cobham, 1964; Edmonds, 1965).
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67c4018b-d50a-45bc-8d78-ced39ee802fb
			- It is important because exponential growth means that even moderately large instances cannot be solved in any reasonable time.
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67c4019c-5274-4cfd-b323-9ead9909b271
		- The theory of **NP-completeness**, pioneered by Cook (1971) and Karp (1972), provides a basis for analyzing the tractability of problems: any problem class to which the class of NPcomplete problems can be reduced is likely to be intractable. (Although it has not been proved that NP-complete problems are necessarily intractable, most theoreticians believe it.)
		  hl-page:: 9
		  ls-type:: annotation
		  id:: 67c401ba-44b5-498a-843b-49e9f6f2b748
		  hl-color:: blue
		  collapsed:: true
			- These results contrast with the optimism with which the popular press greeted the ﬁrst computers—“Electronic Super-Brains” that were “Faster than Einstein!” 
			  ls-type:: annotation
			  hl-page:: 9
			  hl-color:: yellow
			  id:: 67c401d9-2795-4a0c-888f-83182a4f3724
			- Despite the increasing speed of computers, careful use of resources and necessary imperfection will characterize intelligent systems. Put crudely, the world is an *extremely* large problem instance!
			  hl-page:: 9
			  ls-type:: annotation
			  id:: 67c401e8-4318-4498-b8fa-b10fbd31a4ba
			  hl-color:: yellow
	- 1.2.3 Economics
	  ls-type:: annotation
	  hl-page:: 9
	  hl-color:: red
	  id:: 67c401fc-8b36-4c23-bc15-ea3622b4a494
	  collapsed:: true
		- The science of economics originated in 1776, when Adam Smith (1723–1790) published *An Inquiry into the Nature and Causes of the Wealth of Nations*.
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: blue
		  id:: 67c40215-9175-4f0d-bbcd-d071f47bae13
		  collapsed:: true
			- Smith proposed to analyze economies as consisting of many individual agents attending to their own interests
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67c40247-d299-4906-9dc9-cccdb96ccd7e
			- Smith was not, however, advocating ﬁnancial greed as a moral position: his earlier (1759) book *The Theory of Moral Sentiments* begins by pointing out that concern for the well-being of others is an essential component of the interests of every individual.
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67c4026d-e12a-48cf-91db-eb086a2af6c6
		- Most people think of economics as being about money, and indeed the ﬁrst mathematical analysis of decisions under uncertainty, the maximum-expected-value formula of Arnauld(1662), dealt with the monetary value of bets
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: blue
		  id:: 67c4029a-9a38-4071-8633-74a5088a197f
		- [[Daniel Bernoulli]] (1738) noticed that this formula didn’t seem to work well for larger amounts of money, such as investments in maritime trading expeditions.
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: blue
		  id:: 67c402af-82f7-48c6-89e9-0e1c74d07b38
		  hl-stamp:: 1740898995625
		  collapsed:: true
			- He proposed instead a principle based on maximization of expected utility, and explained human investment choices by proposing that the marginal utility of an additional quantity of money diminished as one acquired more money.
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67c402cc-b798-4fef-8194-eba8427dbd2d
		- [[Léon Walras]] (pronounced “Valrasse”) (1834–1910) gave utility theory a more general foundation in terms of preferences between gambles on any outcomes (not just monetary outcomes).
		  hl-page:: 10
		  ls-type:: annotation
		  id:: 67c40301-4e67-4d03-b71f-df4349ad5f1d
		  hl-color:: blue
		  collapsed:: true
			- The theory was improved by Ramsey (1931) and later by [[John von Neumann]] and [[Oskar Morgenstern]] in their book The Theory of Games and Economic Behavior (1944).
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67c4038b-efcb-4be0-9133-cb47a6bb260b
			- Economics is no longer the study of money; rather it is the study of desires and preferences.
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67c403bc-5d3d-4034-a8f8-24360bb21378
		- **Decision theory**, which combines probability theory with utility theory, provides a formal and complete framework for individual decisions (economic or otherwise) made under uncertainty—that is, in cases where probabilistic descriptions appropriately capture the decision maker’s environment.
		  hl-page:: 10
		  ls-type:: annotation
		  id:: 67c403f3-c3df-4bda-83ea-3352fbfd5ac3
		  hl-color:: green
		  collapsed:: true
			- This is suitable for “large” economies where each agent need pay no attention to the actions of other agents as individuals
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67c4041a-69e0-4936-b7e8-f7bb586c26a2
			- For “small” economies, the situation is much more like a **game**: the actions of one player can signiﬁcantly affect the utility of another (either positively or negatively).
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67c40431-5cf1-4676-8a09-a5af9dc2055c
			  hl-stamp:: 1740899448523
		- [[John von Neumann]] and [[Oskar Morgenstern]]’s development of **game theory** (see also Luce and Raiffa, 1957) included the surprising result that, for some games, a rational agent should adopt policies that are (or least appear to be) randomized.
		  hl-page:: 10
		  ls-type:: annotation
		  id:: 67c40444-d00f-4b27-8b4b-8e295967da45
		  hl-color:: green
		  hl-stamp:: 1740899443569
		  collapsed:: true
			- Unlike decision theory, game theory does not offer an unambiguous prescription for selecting actions.
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67c4049d-1585-4c27-be81-3bee7d56be58
		- In AI, decisions involving multiple agents are studied under the heading of **multiagent systems** (Chapter 17).
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: green
		  id:: 67c404a9-d386-4ced-aaa2-b1874f63da36
		- Economists, with some exceptions, did not address the third question listed above: how to make rational decisions when payoffs from actions are not immediate but instead result from several actions taken *in sequence*.
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: blue
		  id:: 67c404c7-bd34-4d6c-a9fd-c7b13d84de4d
		- This topic was pursued in the ﬁeld of **operations research**, which emerged in World War II from efforts in Britain to optimize radar installations, and later found innumerable civilian applications.
		  hl-stamp:: 1740899556482
		  hl-page:: 10
		  ls-type:: annotation
		  id:: 67c404de-9f1d-440d-9052-d4c75fbb3bf8
		  hl-color:: green
		- The work of [[Richard Bellman]] (1957) formalized a class of sequential decision problems called **Markov decision processes**, which we study in Chapter 16 and, under the heading of **reinforcement learning**, in Chapter 23.
		  hl-page:: 10
		  ls-type:: annotation
		  id:: 67c40515-71d1-4860-b59c-6b9f419cf8f3
		  hl-color:: green
		- Work in economics and operations research has contributed much to our notion of rational agents, yet for many years AI research developed along entirely separate paths.
		  ls-type:: annotation
		  hl-page:: 10
		  hl-color:: blue
		  id:: 67c4053d-2504-4d50-ace7-6ced9125b48f
		  collapsed:: true
			- One reason was the apparent complexity of making rational decisions.
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67c40563-a635-4b18-91dc-a14ee5042be4
		- The pioneering AI researcher [[Herbert Simon]] (1916–2001) won the Nobel Prize in economics in 1978 for his early work showing that models based on **satisﬁcing**—making decisions that are “good enough,” rather than laboriously calculating an optimal decision—gave a better description of actual human behavior (Simon, 1947).
		  hl-page:: 10
		  ls-type:: annotation
		  id:: 67c40574-5a9f-4685-bd28-77b3ca1829c2
		  hl-color:: blue
		  collapsed:: true
			- Since the 1990s, there has been a resurgence of interest in decisiontheoretic techniques for AI.
			  ls-type:: annotation
			  hl-page:: 10
			  hl-color:: yellow
			  id:: 67c405a3-3123-4f8e-b76c-b0c1eea67475
	- 1.2.4 Neuroscience
	  ls-type:: annotation
	  hl-page:: 11
	  hl-color:: red
	  id:: 67c405b4-577c-4366-b309-e105b27e6d86
	  collapsed:: true
		- **Neuroscience** is the study of the nervous system, particularly the brain.
		  ls-type:: annotation
		  hl-page:: 11
		  hl-color:: blue
		  id:: 67c405d0-d9a0-4116-bf57-52b06eedaa69
		  collapsed:: true
			- Although the exact way in which the brain enables thought is one of the great mysteries of science, the fact that it does enable thought has been appreciated for thousands of years because of the evidence that strong blows to the head can lead to mental incapacitation.
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: yellow
			  id:: 67c405ee-56a8-4688-8e07-e177560d06a2
			- It has also long been known that human brains are somehow different; in about 335 BCE Aristotle wrote, “Of all the animals, man has the largest brain in proportion to his size.”[^6]
			  hl-page:: 11
			  ls-type:: annotation
			  id:: 67c4060a-96e3-448b-842f-e70eec1b03d4
			  hl-color:: yellow
				- hl-page:: 11
				  ls-type:: annotation
				  id:: 67c4061d-0a3f-4172-a933-1252532db234
				  hl-color:: purple
				  [^6]:It has since been discovered that the tree shrew and some bird species exceed the human brain/body ratio.
			- Still, it was not until the middle of the18th century that the brain was widely recognized as the seat of consciousness. Before then, candidate locations included the heart and the spleen.
			  ls-type:: annotation
			  hl-page:: 11
			  hl-color:: yellow
			  id:: 67c4063b-a24e-4b4e-96e7-a304311412e4
		- [[Paul Broca]]’s (1824–1880) investigation of aphasia (speech deﬁcit) in brain-damaged patients in 1861 initiated the study of the brain’s functional organization by identifying a localized area in the left hemisphere—now called Broca’s area—that is responsible for speech production.[^7]
		  hl-page:: 11
		  ls-type:: annotation
		  id:: 67c40659-3bd3-45e2-ab74-92cb6a998783
		  hl-color:: blue
		  collapsed:: true
			- hl-page:: 11
			  ls-type:: annotation
			  id:: 67c40673-419a-422e-906b-4e64b2ced7ba
			  hl-color:: purple
			  [^7]:Many cite Alexander Hood (1824) as a possible prior source.
		- By that time, it was known that the brain consisted largely of nerve cells, or **neurons**, but it was not until 1873 that [[Camillo Golgi]] (1843–1926) developed a staining technique allowing the observation of individual neurons (see **Figure 1.1**).
		  hl-stamp:: 1740900025560
		  hl-page:: 11
		  ls-type:: annotation
		  id:: 67c406b6-b014-48a5-907d-52dc85fa8345
		  hl-color:: green
		  collapsed:: true
			- [:span]
			  ls-type:: annotation
			  hl-page:: 12
			  hl-color:: yellow
			  id:: 67c406e7-aa83-46d7-b897-9ce5cb770eb0
			  hl-type:: area
			  hl-stamp:: 1740900070394
		- Brains and digital computers have somewhat different properties. **Figure 1.2** shows that computers have a cycle time that is a million times faster than a brain.
		  ls-type:: annotation
		  hl-page:: 12
		  hl-color:: blue
		  id:: 67c4071f-6618-49db-9329-dda117afea20
		  collapsed:: true
			- The brain makes up for that with far more storage and interconnection than even a high-end personal computer, although the largest supercomputers match the brain on some metrics.
			  ls-type:: annotation
			  hl-page:: 12
			  hl-color:: yellow
			  id:: 67c40756-bd74-47f1-913b-23053a20e96c
			- [:span]
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: yellow
			  id:: 67c4073d-e8af-4963-ba45-6be4b8a473f5
			  hl-type:: area
			  hl-stamp:: 1740900156069
		- Futurists make much of these numbers, pointing to an approaching singularity at which computers reach a su-Singularity perhuman level of performance (Vinge, 1993; Kurzweil, 2005; Doctorow and Stross, 2012), and then rapidly improve themselves even further. 
		  ls-type:: annotation
		  hl-page:: 12
		  hl-color:: green
		  id:: 67c40765-4797-45ff-b42d-f909d16ee53c
		  collapsed:: true
			- But the comparisons of raw numbers are not especially informative. Even with a computer of virtually unlimited capacity, we still require further conceptual breakthroughs in our understanding of intelligence (see Chapter 29).
			  ls-type:: annotation
			  hl-page:: 12
			  hl-color:: yellow
			  id:: 67c40784-76fe-4fc8-bb52-339858a6b304
			- Crudely put, without the right theory, faster machines just give you the wrong answer faster
			  ls-type:: annotation
			  hl-page:: 12
			  hl-color:: yellow
			  id:: 67c4078e-81b8-4ecd-a023-c66d283b3237
	- 1.2.5 Psychology
	  ls-type:: annotation
	  hl-page:: 12
	  hl-color:: red
	  id:: 67c40797-ec2f-4a02-b561-ba18b3a0ae2b
	  collapsed:: true
		- The origins of scientiﬁc psychology are usually traced to the work of the German physicist [[Hermann von Helmholtz]] (1821–1894) and his student [[Wilhelm Wundt]] (1832–1920).
		  ls-type:: annotation
		  hl-page:: 12
		  hl-color:: blue
		  id:: 67c407c1-3eb2-4a90-97af-89b643ac34cb
		  collapsed:: true
			- Helmholtz applied the scientiﬁc method to the study of human vision, and his *Handbook of Physiological Optics* has been described as “the single most important treatise on the physics and physiology of human vision” (Nalwa, 1993, p.15).
			  ls-type:: annotation
			  hl-page:: 12
			  hl-color:: yellow
			  id:: 67c407e5-5db5-4201-a02d-f3241fb907f3
			- In 1879, Wundt opened the ﬁrst laboratory of experimental psychology, at the University of Leipzig.
			  ls-type:: annotation
			  hl-page:: 12
			  hl-color:: yellow
			  id:: 67c40803-bb97-497e-88b1-25ef7434827e
			- Wundt insisted on carefully controlled experiments in which his workers would perform a perceptual or associative task while introspecting on their thought processes.
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: yellow
			  id:: 67c40819-d7e8-44f3-9a18-312b76f5318b
			- The careful controls went a long way toward making psychology a science, but the subjective nature of the data made it unlikely that experimenters would ever disconﬁrm their own theories.
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: yellow
			  id:: 67c4082f-674a-49b0-86d6-39f3ed316996
		- Biologists studying animal behavior, on the other hand, lacked introspective data and developed an objective methodology, as described by [[H. S. Jennings]] (1906) in his inﬂuential work *Behavior of the Lower Organisms*.
		  hl-page:: 13
		  ls-type:: annotation
		  id:: 67c40856-b14d-4245-8c73-165d3649f2fa
		  hl-color:: blue
		- Applying this viewpoint to humans, the **behaviorism** movement, led by [[John Watson]] (1878–1958), rejected any theory involving mental processes on the grounds that introspection could not provide reliable evidence.
		  hl-page:: 13
		  ls-type:: annotation
		  id:: 67c40878-6fd9-46bb-90b2-5a0beb3df77a
		  hl-color:: green
		  collapsed:: true
			- Behaviorists insisted on studying only objective measures of the percepts (or *stimulus*) given to an animal and its resulting actions (or *response*).
			  hl-page:: 13
			  ls-type:: annotation
			  id:: 67c408a2-5914-428e-aeb1-0d094fb9d787
			  hl-color:: yellow
			- Behaviorism discovered a lot about rats and pigeons but had less success at understanding humans.
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: yellow
			  id:: 67c408b8-b294-4281-8b3d-4a4a118a60a9
		- **Cognitive psychology**, which views the brain as an information-processing device, can be traced back at least to the works of [[William James]] (1842–1910).
		  hl-page:: 13
		  ls-type:: annotation
		  id:: 67c408cf-e02c-4e7d-b85e-19159f636363
		  hl-color:: green
		  collapsed:: true
			- Helmholtz also insisted that perception involved a form of unconscious logical inference.
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: yellow
			  id:: 67c408fd-2c93-45dd-bd78-db69881a976a
		- The cognitive viewpoint was largely eclipsed by behaviorism in the United States, but at Cambridge’s Applied Psychology Unit, directed by [[Frederic Bartlett]] (1886–1969), cognitive modeling was able to ﬂourish.
		  ls-type:: annotation
		  hl-page:: 13
		  hl-color:: blue
		  id:: 67c4090f-9795-456d-aa2e-74b5384a6554
		  collapsed:: true
			- *The Nature of Explanation*, by Bartlett’s student and successor [[Kenneth Craik]] (1943), forcefully reestablished the legitimacy of such “mental” terms as beliefs and goals, arguing that they are just as scientiﬁc as, say, using pressure and temperature to talk about gases, despite gasses being made of molecules that have neither.
			  hl-page:: 13
			  ls-type:: annotation
			  id:: 67c40932-4ab5-4cc2-9826-b1256086277e
			  hl-color:: yellow
		- Craik speciﬁed the three key steps of a knowledge-based agent
		  ls-type:: annotation
		  hl-page:: 13
		  hl-color:: blue
		  id:: 67c40969-7b64-477d-89a4-2646af1f6989
		  collapsed:: true
			- (1) the stimulus must be translated into an internal representation,
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: yellow
			  id:: 67c4096e-3549-4e02-8c0b-46a352b8ddce
			- (2) the representation is manipulated by cognitive processes to derive new internal representations, and
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: yellow
			  id:: 67c40977-4bfb-4dd6-b2f8-1dd081ecff8d
			- (3) these are in turn retranslated back into action. He clearly explained why this was a good design for an agent:
			  ls-type:: annotation
			  hl-page:: 13
			  hl-color:: yellow
			  id:: 67c40980-7102-42df-8956-c4d56f878234
			- ls-type:: annotation
			  hl-page:: 13
			  hl-color:: yellow
			  id:: 67c409b2-fd80-416f-938b-3c6bc8fa33cf
			  >If the organism carries a “small-scale model” of external reality and of its own possible actions within its head, it is able to try out various alternatives, conclude which is the best of them, react to future situations before they arise, utilize the knowledge of past events in dealing with the present and future, and in every way to react in a much fuller, safer, and more competent manner to the emergencies which face it. (Craik, 1943)
		- After Craik’s death in a bicycle accident in 1945, his work was continued by [[Donald Broadbent]], whose book *Perception and Communication* (1958) was one of the ﬁrst works to model psychological phenomena as information processing.
		  hl-page:: 14
		  ls-type:: annotation
		  id:: 67c40b2a-9884-49ea-8f75-271b6bcf5093
		  hl-color:: blue
		- Meanwhile, in the United States, the development of computer modeling led to the creation of the ﬁeld of **cognitive science**.
		  ls-type:: annotation
		  hl-page:: 14
		  hl-color:: green
		  id:: 67c40b53-e292-4ae8-9025-137e0a92cffa
		  collapsed:: true
			- Theﬁeld can be said to have started at a workshop in September 1956 at MIT—just two months after the conference at which AI itself was “born.”
			  ls-type:: annotation
			  hl-page:: 14
			  hl-color:: yellow
			  id:: 67c40b61-c28e-4120-b92c-3058730d511d
		- At the workshop, George Miller presented *The Magic Number Seven*, Noam Chomsky presented *Three Models of Language*, and Allen Newell and Herbert Simon presented *The Logic Theory Machine*.
		  hl-page:: 14
		  ls-type:: annotation
		  id:: 67c40bce-8b95-400c-b55a-dae0844190f3
		  hl-color:: blue
		  collapsed:: true
			- These three inﬂuential papers showed how computer models could be used to address the psychology of memory, language, and logical thinking, respectively.
			  ls-type:: annotation
			  hl-page:: 14
			  hl-color:: yellow
			  id:: 67c40c05-750e-4904-a18e-34270cd4eafe
			- It is now a common (although far from universal) view among psychologists that “a cognitive theory should be like a computer program” (Anderson, 1980); that is, it should describe the operation of a cognitive function in terms of the processing of information.
			  ls-type:: annotation
			  hl-page:: 14
			  hl-color:: yellow
			  id:: 67c40c26-762c-4d73-8d74-4b85ce5591d0
		- For purposes of this review, we will count the ﬁeld of **human–computer interaction** (HCI) under psychology.
		  hl-page:: 14
		  ls-type:: annotation
		  id:: 67c40c37-112e-4a83-8735-ff35da9caa9d
		  hl-color:: green
		- [[Doug Engelbart]], one of the pioneers of HCI, championed the idea of **intelligence augmentation**—IA rather than AI.
		  hl-page:: 14
		  ls-type:: annotation
		  id:: 67c40c4d-6632-4a89-b0dd-1864b08b7c0d
		  hl-color:: green
		  collapsed:: true
			- He believed that computers should augment human abilities rather than automate away human tasks.
			  hl-page:: 14
			  ls-type:: annotation
			  id:: 67c40c8c-ab4b-4e64-a941-cbdbbe25fdbc
			  hl-color:: yellow
			- In 1968, Engelbart’s “mother of all demos” showed off for the ﬁrst time the computer mouse, a windowing system, hypertext, and video conferencing—all in an effort to demonstrate what human knowledge workers could collectively accomplish with some intelligence augmentation.
			  ls-type:: annotation
			  hl-page:: 14
			  hl-color:: yellow
			  id:: 67c40cae-0115-424f-a615-2828572e95c6
		- Today we are more likely to see IA and AI as two sides of the same coin, with the former emphasizing human control and the latter emphasizing intelligent behavior on the part of the machine. Both are needed for machines to be useful to humans.
		  ls-type:: annotation
		  hl-page:: 14
		  hl-color:: blue
		  id:: 67c40d31-6f02-4c3d-ade7-558024d5a57d
	- 1.2.6 Computer engineering
	  ls-type:: annotation
	  hl-page:: 14
	  hl-color:: red
	  id:: 67c40d54-a4d4-4053-983d-087c00a19ec2
	  collapsed:: true
		- The modern digital electronic computer was invented independently and almost simultaneously by scientists in three countries embattled in World War II.
		  ls-type:: annotation
		  hl-page:: 14
		  hl-color:: blue
		  id:: 67c40de9-188b-4c21-a192-5694a363e916
		  collapsed:: true
			- The ﬁrst *operational* computer was the electromechanical Heath Robinson,[^9] built in 1943 by Alan Turing’s team for a single purpose: deciphering German messages.
			  hl-page:: 14
			  ls-type:: annotation
			  id:: 67c40e0a-ee72-4345-b4d3-f8aab19123e4
			  hl-color:: yellow
				- hl-page:: 14
				  ls-type:: annotation
				  id:: 67c40eb9-217c-4b69-91c8-e8394a7c9db7
				  hl-color:: purple
				  [^9]:A complex machine named after a British cartoonist who depicted whimsical and absurdly complicated contraptions for everyday tasks such as buttering toast.
			- In 1943, the same group developed the Colossus, a powerful general-purpose machine based on vacuum tubes.[^10]
			  hl-page:: 14
			  ls-type:: annotation
			  id:: 67c40ea7-2398-4777-a14e-7f1c442e97da
			  hl-color:: yellow
				- hl-page:: 14
				  ls-type:: annotation
				  id:: 67c40ed2-8189-4166-9ed7-8bdeda5c76c9
				  hl-color:: purple
				  [^10]:In the postwar period, Turing wanted to use these computers for AI research—for example, he created an outline of the ﬁrst chess program (Turing et al., 1953)—but the British government blocked this research.
		- The ﬁrst operational *programmable* computer was the Z-3, the invention of [[Konrad Zuse]] in Germany in1941.
		  hl-page:: 14
		  ls-type:: annotation
		  id:: 67c40eeb-07fd-460a-9530-c249578caaa1
		  hl-color:: blue
		  collapsed:: true
			- Zuse also invented ﬂoating-point numbers and the ﬁrst high-level programming language, Plankalkül.
			  hl-page:: 14
			  ls-type:: annotation
			  id:: 67c40f24-52a4-4621-8169-a812505a9080
			  hl-color:: yellow
		- The ﬁrst *electronic* computer, the ABC, was assembled by [[John Atanasoff]] and his student [[Clifford Berry]] between 1940 and 1942 at Iowa State University
		  hl-page:: 14
		  ls-type:: annotation
		  id:: 67c40f70-a6ab-4982-8132-a790a86f000c
		  hl-color:: blue
		  hl-stamp:: 1740902307036
		  collapsed:: true
			- Atanasoff’s research received little support or recognition; it was the ENIAC, developed as part of a secret military project at the University of Pennsylvania by a team including John Mauchly and J. Presper Eckert, that proved to be the most inﬂuential forerunner of modern computers.
			  ls-type:: annotation
			  hl-page:: 14
			  hl-color:: yellow
			  id:: 67c40f9f-e3e7-44e3-8275-dec1c4bffe06
		- Since that time, each generation of computer hardware has brought an increase in speed and capacity and a decrease in price—a trend captured in **Moore’s law**.
		  ls-type:: annotation
		  hl-page:: 14
		  hl-color:: green
		  id:: 67c40fc7-4328-4140-b108-20c159d09739
		  collapsed:: true
			- Performance doubled every 18 months or so until around 2005, when power dissipation problems led manufacturers to start multiplying the number of CPU cores rather than the clock speed.
			  hl-page:: 14
			  ls-type:: annotation
			  id:: 67c40fda-d2d1-4c6c-a815-10fc92ecf380
			  hl-color:: yellow
			- Current expectations are that future increases in functionality will come from massive parallelism—a curious convergence with the properties of the brain. 
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: yellow
			  id:: 67c4100c-0344-4821-86e1-1189bf497468
			- We also see new hardware designs based on the idea that in dealing with an uncertain world, we don’t need 64 bits of precision in our numbers; just 16 bits (as in the bfloat16 format) or even 8 bits will be enough, and will enable faster processing.
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: yellow
			  id:: 67c41069-3321-4a79-992e-3172024759ec
		- We are just beginning to see hardware tuned for AI applications, such as the graphics processing unit (GPU), tensor processing unit (TPU), and wafer scale engine (WSE).
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: blue
		  id:: 67c41089-2ca8-414d-b3c1-f044f132e095
		  collapsed:: true
			- From the 1960s to about 2012, the amount of computing power used to train top machine learning applications followed Moore’s law.
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: yellow
			  id:: 67c410e9-8ea3-400e-83ec-336c7c64a252
			- Beginning in 2012, things changed: from 2012 to2018 there was a 300,000-fold increase, which works out to a doubling every 100 days or so (Amodei and Hernandez, 2018).
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: yellow
			  id:: 67c41109-831a-4323-8b22-3129672164f1
			- A machine learning model that took a full day to train in 2014 takes only two minutes in 2018 (Ying et al., 2018).
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: yellow
			  id:: 67c4112d-f434-47ca-b043-28c0ebb3123d
		- Although it is not yet practical, **quantum computing** holds out the promise of far greater accelerations for some important subclasses of AI algorithms.
		  hl-page:: 15
		  ls-type:: annotation
		  id:: 67c41137-0d95-4356-8a96-fd614f44447e
		  hl-color:: green
		- Of course, there were calculating devices before the electronic computer. The earliest automated machines, dating from the 17th century, were discussed on page 24.
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: blue
		  id:: 67c41179-0017-4ebd-9511-ee80634770fe
		- The ﬁrst programmable machine was a loom, devised in 1805 by [[Joseph Marie Jacquard]] (1752–1834), that used punched cards to store instructions for the pattern to be woven.
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: blue
		  id:: 67c4118e-37d0-4b63-95dc-7bf419753012
		- In the mid-19th century, [[Charles Babbage]] (1792–1871) designed two computing machines, neither of which he completed.
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: blue
		  id:: 67c411b4-c33d-4ac1-a709-5fca71ed4bac
		  collapsed:: true
			- The Difference Engine was intended to compute mathematical tables for engineering and scientiﬁc projects. It was ﬁnally built and shown to work in 1991 (Swade, 2000).
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: yellow
			  id:: 67c411f8-7c4e-4012-a8f0-a38720fa3f83
			- Babbage’s Analytical Engine was far more ambitious: it included addressable memory, stored programs based on Jacquard’s punched cards, and conditional jumps. It was the ﬁrst machine capable of universal computation.
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: yellow
			  id:: 67c41208-dddd-4154-b263-f10a15ef09bf
		- Babbage’s colleague [[Ada Lovelace]], daughter of the poet [[Lord Byron]], understood its potential, describing it as “a thinking or . . . a reasoning machine,” one capable of reasoning about “all subjects in the universe” (Lovelace, 1843).
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: blue
		  id:: 67c41239-6867-4c39-8c0d-fb4e2ee5b865
		  collapsed:: true
			- She also anticipated AI’s hype cycles, writing, “It is desirable to guard against the possibility of exaggerated ideas that might arise as to the powers of the Analytical Engine.” Unfortunately, Babbage’s machines and Lovelace’s ideas were largely forgotten.
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: yellow
			  id:: 67c41262-d870-405a-aec1-5c0985bf657c
		- AI also owes a debt to the software side of computer science, which has supplied the operating systems, programming languages, and tools needed to write modern programs (and papers about them)
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: blue
		  id:: 67c412d2-055b-418f-a11f-e8e36c8ab958
		  collapsed:: true
			- But this is one area where the debt has been repaid: work in AI has pioneered many ideas that have made their way back to mainstream computer science, including time sharing, interactive interpreters, personal computers with windows and mice, rapid development environments, the linked-list data type, automatic storage management, and key concepts of symbolic, functional, declarative, and object-oriented programming.
			  ls-type:: annotation
			  hl-page:: 15
			  hl-color:: yellow
			  id:: 67c412f4-389a-4c00-8eba-29d8e9681411
- 1.2.7 Control theory and cybernetics
  ls-type:: annotation
  hl-page:: 15
  hl-color:: red
  id:: 67c41313-10e0-48d1-9240-7d8bfc5e485a
	- [[Ktesibios of Alexandria]] (c. 250 BCE) built the ﬁrst self-controlling machine: a water clock with a regulator that maintained a constant ﬂow rate.
	  ls-type:: annotation
	  hl-page:: 15
	  hl-color:: blue
	  id:: 67c41341-7e39-4108-8e98-ebcdbff85dd1
	  collapsed:: true
		- This invention changed the deﬁnition of what an artifact could do. Previously, only living things could modify their behavior in response to changes in the environment.
		  ls-type:: annotation
		  hl-page:: 15
		  hl-color:: yellow
		  id:: 67c41415-ef6b-411e-9be0-b7bd5ce3215a
	- Other examples of self-regulating feedback control systems include the steam engine governor, created by [[James Watt]] (1736–1819), and the thermostat, invented by [[Cornelis Drebbel]] (1572–1633), who also invented the submarine.
	  hl-page:: 15
	  ls-type:: annotation
	  id:: 67c4142d-2bf2-4d57-9d4f-546d8cdbfabb
	  hl-color:: blue
	- [[James Clerk Maxwell]] (1868) initiated the mathematical theory of control systems.
	  ls-type:: annotation
	  hl-page:: 16
	  hl-color:: blue
	  id:: 67c4145f-13e6-4595-9fc3-6c12dad77487
	  hl-stamp:: 1740903595765
	- A central ﬁgure in the post-war development of **control theory** was [[Norbert Wiener]] (1894–1964).
	  hl-page:: 16
	  ls-type:: annotation
	  id:: 67c41489-45a9-43c3-ac19-358ff55a73a1
	  hl-color:: green
	  hl-stamp:: 1740903768804
	- Wiener was a brilliant mathematician who worked with [[Bertrand Russell,]] among others, before developing an interest in biological and mechanical control systems and their connection to cognition.
	  ls-type:: annotation
	  hl-page:: 16
	  hl-color:: blue
	  id:: 67c414c1-9ebd-4053-a013-97113d14b433
- Like [[Kenneth Craik]] (who also used control systems as psychological models), [[Norbert Wiener]] and his colleagues [[Arturo Rosenblueth]] and [[Julian Bigelow]] challenged the behaviorist orthodoxy (Rosenblueth et al., 1943).
  hl-page:: 16
  ls-type:: annotation
  id:: 67c41538-7c22-4551-8c4a-315c5d165be4
  hl-color:: blue
- They viewed purposive behavior as arising from a regulatory mechanism trying to minimize “error”—the difference between current state and goal state
  ls-type:: annotation
  hl-page:: 16
  hl-color:: yellow
  id:: 67c41599-4427-465d-a0c1-fb89940480bf