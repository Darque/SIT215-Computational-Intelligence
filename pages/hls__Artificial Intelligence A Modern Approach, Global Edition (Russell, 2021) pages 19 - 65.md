file:: [Artificial Intelligence A Modern Approach, Global Edition (Russell, 2021) pages 19 - 65.pdf](../assets/Artificial Intelligence A Modern Approach, Global Edition (Russell, 2021) pages 19 - 65.pdf)
file-path:: ../assets/Artificial Intelligence A Modern Approach, Global Edition (Russell, 2021) pages 19 - 65.pdf

- Chapter 1 - Introduction
  hl-page:: 1
  ls-type:: annotation
  id:: 67c2612d-5964-4e19-8def-fceb67b6ad0c
  hl-color:: red
	- We call ourselves Homo sapiens—man the wise—because our **intelligence** is so important to us.
	  hl-page:: 1
	  ls-type:: annotation
	  id:: 67c2615c-e9bb-4e59-ad96-6d356b565fd5
	  hl-color:: blue
	  collapsed:: true
		- For thousands of years, we have tried to understand *how we think and act*—that is, how our brain, a mere handful of matter, can perceive, understand, predict, and manipulate a world far larger and more complicated than itself
		  ls-type:: annotation
		  hl-page:: 1
		  hl-color:: yellow
		  id:: 67c26179-f254-46f3-85bf-bfb9b461d929
		- The ﬁeld of **artiﬁcial intelligence**, or AI, is concerned with not just understanding but also building intelligent entities—machines that can compute how to act effectively and safely in a wide variety of novel situations.
		  hl-page:: 1
		  ls-type:: annotation
		  id:: 67c2619e-ea5a-47bd-821f-dd6595aaef1b
		  hl-color:: yellow
	- Surveys regularly rank AI as one of the most interesting and fastest-growing ﬁelds, and it is already generating over a trillion dollars a year in revenue.
	  ls-type:: annotation
	  hl-page:: 1
	  hl-color:: blue
	  id:: 67c261d1-d775-4f1f-a362-9890a1232594
	  collapsed:: true
		- AI expert Kai-Fu Lee predicts that its impact will be “more than anything in the history of mankind.” Moreover, the intellectual frontiers of AI are wide open.
		  ls-type:: annotation
		  hl-page:: 1
		  hl-color:: yellow
		  id:: 67c26256-3bf3-40d0-8071-78558b1f73a9
		- Whereas a student of an older science such as physics might feel that the best ideas have already been discovered by Galileo, Newton, Curie, Einstein, and the rest, AI still has many openings for full-time masterminds.
		  ls-type:: annotation
		  hl-page:: 1
		  hl-color:: yellow
		  id:: 67c26269-3a27-4d28-b8c8-7da1ee0309f3
	- AI currently encompasses a huge variety of subﬁelds, ranging from the general (learning, reasoning, perception, and so on) to the speciﬁc, such as playing chess, proving mathematical theorems, writing poetry, driving a car, or diagnosing diseases. AI is relevant to any intellectual task; it is truly a universal ﬁeld.
	  ls-type:: annotation
	  hl-page:: 1
	  hl-color:: blue
	  id:: 67c26286-8477-4269-aeb4-4dbcca9dd441
	- 1.1 What Is AI?
	  ls-type:: annotation
	  hl-page:: 1
	  hl-color:: red
	  id:: 67c26296-96fc-4439-9734-993ae22073da
		- We have claimed that AI is interesting, but we have not said what it is.
		  ls-type:: annotation
		  hl-page:: 1
		  hl-color:: blue
		  id:: 67c262a7-990c-46a0-a4bb-25033dcbeb3c
		  collapsed:: true
			- Historically, researchers have pursued several different versions of AI. Some have deﬁned intelligence in terms of ﬁdelity to human performance, while others prefer an abstract, formal deﬁnition of intelligence called:
			  ls-type:: annotation
			  hl-page:: 1
			  hl-color:: yellow
			  id:: 67c262bf-f095-42b5-9c8a-79d49acb81bd
			- **rationality**—loosely speaking, doing the “right thing.” The subject matter Rationality itself also varies: some consider intelligence to be a property of internal thought processes and reasoning, while others focus on intelligent behavior, an external characterization.[^1]
			  hl-page:: 1
			  ls-type:: annotation
			  id:: 67c262d3-01bf-4b76-9d06-6597cdec236b
			  hl-color:: green
				- hl-page:: 1
				  ls-type:: annotation
				  id:: 67c26312-4c02-41c1-83f0-ff8566537c1f
				  hl-color:: purple
				  hl-stamp:: 1740792672097
				  [^1]:In the public eye, there is sometimes confusion between the terms “artiﬁcial intelligence” and “machine learning.” Machine learning is a subﬁeld of AI that studies the ability to improve performance based on experience. Some AI systems use machine learning methods to achieve competence, but some do not.
		- From these two dimensions—human vs. rational[^2] and thought vs. behavior—there are four possible combinations, and there have been adherents and research programs for all four.
		  hl-page:: 1
		  ls-type:: annotation
		  id:: 67c26326-4acd-4bbf-9994-53df7478f6e3
		  hl-color:: blue
		  collapsed:: true
			- The methods used are necessarily different: the pursuit of human-like intelligence must be in part an empirical science related to psychology, involving observations and hypotheses about actual human behavior and thought processes; a rationalist approach, on the other hand, involves a combination of mathematics and engineering, and connects to statistics, control theory, and economics.
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: yellow
			  id:: 67c263c0-7c96-4e43-96c7-46e8bb867556
			- The various groups have both disparaged and helped each other. Let us look at the four approaches in more detail.
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: yellow
			  id:: 67c263c9-0d87-4808-9316-2c8a142879b5
			- hl-page:: 1
			  ls-type:: annotation
			  id:: 67c2635d-e87e-40cb-a72c-869f03713613
			  hl-color:: purple
			  [^2]:We are not suggesting that humans are “irrational” in the dictionary sense of “deprived of normal mental clarity.” We are merely conceding that human decisions are not always mathematically perfect.
		- 1.1.1 Acting humanly: The Turing test approach
		  ls-type:: annotation
		  hl-page:: 2
		  hl-color:: red
		  id:: 67c263f3-a8f6-43d7-beba-a044b66cb059
		  collapsed:: true
			- The **Turing test**, proposed by Alan Turing (1950), was designed as a thought experiment thatTuring test would sidestep the philosophical vagueness of the question “Can a machine think?
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: green
			  id:: 67c26420-84bc-47fe-8bd4-f785cdd57fab
			  collapsed:: true
				- A computer passes the test if a human interrogator, after posing some written questions, cannot tell whether the written responses come from a person or from a computer. Chapter 28 discusses the details of the test and whether a computer would really be intelligent if it passed.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: yellow
				  id:: 67c26442-fbdf-4b83-8cef-a500958fc50e
			- For now, we note that programming a computer to pass a rigorously applied test provides plenty to work on. The computer would need the following capabilities:
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: green
			  id:: 67c26455-35ea-4175-825a-969362e70274
			  hl-stamp:: 1740792925206
			  collapsed:: true
				- **natural language processing** to communicate successfully in a human language;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26479-0d66-44d4-88fa-98c9b3b07fbd
				- **knowledge representation** to store what it knows or hears;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26487-f746-4560-a935-da0c1e69d34e
				- **automated reasoning** to answer questions and to draw new conclusions;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26496-1246-4e34-abe4-f32b4baf880f
				- **machine learning** to adapt to new circumstances and to detect and extrapolate patterns.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c264a6-4ab8-4a2d-8d75-fb9855410bb0
			- Turing viewed the *physical* simulation of a person as unnecessary to demonstrate intelligence.
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: blue
			  id:: 67c265c0-7598-484c-a09d-e95ef32a9043
			- However, other researchers have proposed a **total Turing test**, which requires interaction withTotal Turing test objects and people in the real world. To pass the total Turing test, a robot will need
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: green
			  id:: 67c26605-a21e-4528-9d10-97e7b355c99e
			  collapsed:: true
				- **computer vision** and speech recognition to perceive the world;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c2662a-4721-4dcf-946b-9245814b01cd
				- **robotics** to manipulate objects and move about.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26637-a688-40f8-b256-f0a002272c0a
			- These six disciplines compose most of AI. Yet AI researchers have devoted little effort to passing the Turing test, believing that it is more important to study the underlying principles of intelligence.
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: blue
			  id:: 67c26655-00f4-4a6b-aaa3-0b27d1c07f00
				- The quest for “artiﬁcial ﬂight” succeeded when engineers and inventors stopped imitating birds and started using wind tunnels and learning about aerodynamics.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: yellow
				  id:: 67c266a7-b3f1-4cb8-aeb4-b9a7e7c15778
				- Aeronautical engineering texts do not deﬁne the goal of their ﬁeld as making “machines thatﬂy so exactly like pigeons that they can fool even other pigeons.”
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: yellow
				  id:: 67c266b2-ae44-4312-a990-da62f2f293aa
		- 1.1.2 Thinking humanly: The cognitive modeling approach
		  ls-type:: annotation
		  hl-page:: 2
		  hl-color:: red
		  id:: 67c266d8-ced1-4bab-b2ce-e81ea5be2ab4
		  collapsed:: true
			- To say that a program thinks like a human, we must know how humans think. We can learn about human thought in three ways:
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: blue
			  id:: 67c266ff-343b-44fe-9c11-14e29d7412a2
			  collapsed:: true
				- **introspection**—trying to catch our own thoughts as they go by;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26766-9473-4d7c-adc0-4e62679a9fdb
				- **psychological experiments**—observing a person in action;
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c26787-9d44-4496-b692-5478b2edfabb
				- **brain imaging**—observing the brain in action.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: green
				  id:: 67c267b1-53d9-4746-8900-0db35edc5ab2
			- Once we have a sufﬁciently precise theory of the mind, it becomes possible to express the theory as a computer program.
			  ls-type:: annotation
			  hl-page:: 2
			  hl-color:: blue
			  id:: 67c267e6-85a1-4dbf-85be-a14d77fe1763
			  collapsed:: true
				- If the program’s input–output behavior matches corresponding human behavior, that is evidence that some of the program’s mechanisms could also be operating in humans.
				  ls-type:: annotation
				  hl-page:: 2
				  hl-color:: yellow
				  id:: 67c26866-0b52-4ad5-89f7-7cf38b4c00c0
			- For example, Allen Newell and Herbert Simon, who developed GPS, the “General Problem Solver” (Newell and Simon, 1961), were not content merely to have their program solve problems correctly.
			  hl-page:: 2
			  ls-type:: annotation
			  id:: 67c26879-c7b1-4c94-80fa-b27e99e48639
			  hl-color:: blue
			  collapsed:: true
				- They were more concerned with comparing the sequence and timing of its reasoning steps to those of human subjects solving the same problems
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c26891-23ee-49da-b967-343fb56d15fb
			- The interdisciplinary ﬁeld of **cognitive science** brings together computer models from AI and experimental techniques from psychology to construct precise and testable theories of the human mind.
			  hl-page:: 3
			  ls-type:: annotation
			  id:: 67c2689e-d4cd-4f25-9875-6544f9853478
			  hl-color:: green
			- Cognitive science is a fascinating ﬁeld in itself, worthy of several textbooks and at least one encyclopedia (Wilson and Keil, 1999).
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: blue
			  id:: 67c268ea-b5a3-4549-932e-6018bacdcbee
			  collapsed:: true
				- We will occasionally comment on similarities or differences between AI techniques and human cognition. 
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c268fb-a870-4087-b370-ca59c4a42d99
				- Real cognitive science, however, is necessarily based on experimental investigation of actual humans or animals. We will leave that for other books, as we assume the reader has only a computer for experimentation.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c26917-35aa-4a2e-85ca-cfaab0f95a36
			- In the early days of AI there was often confusion between the approaches. An author would argue that an algorithm performs well on a task and that it is *therefore* a good model of human performance, or vice versa.
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: blue
			  id:: 67c26948-19ce-4d42-b3eb-6a378eaf2e78
				- Modern authors separate the two kinds of claims; this distinction has allowed both AI and cognitive science to develop more rapidly.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c2695f-054a-4c70-98b4-a19404ddfa7e
				- The two ﬁelds fertilize each other, most notably in computer vision, which incorporates neurophysiological evidence into computational models.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c269b3-9df8-4ac6-acbf-735a2f8d831f
				- Recently, the combination of neuroimaging methods combined with machine learning techniques for analyzing such data has led to the beginnings of a capability to “read minds”—that is, to ascertain the semantic content of a person’s inner thoughts. This capability could, in turn, shed further light on how human cognition works.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c269d0-3ff3-493d-a979-bdbe28577808
		- 1.1.3 Thinking rationally: The “laws of thought” approach
		  ls-type:: annotation
		  hl-page:: 3
		  hl-color:: red
		  id:: 67c269e1-d009-4476-8221-3bda36c35de6
		  collapsed:: true
			- The Greek philosopher Aristotle was one of the ﬁrst to attempt to codify “right thinking”— that is, irrefutable reasoning processes.
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: blue
			  id:: 67c269fb-1070-4a2b-99a8-57a3d89a5692
			  collapsed:: true
				- His **syllogisms** provided patterns for argument structures that always yielded correct conclusions when given correct premises
				  hl-page:: 3
				  ls-type:: annotation
				  id:: 67c26aab-fda6-4598-a320-645752cc7159
				  hl-color:: green
				  collapsed:: true
					- The canonical example starts with *Socrates is a man and all men are mortal* and concludes that *Socrates is mortal*. (This example is probably due to Sextus Empiricus rather than Aristotle.)
					  hl-page:: 3
					  ls-type:: annotation
					  id:: 67c26ad5-d8c3-4ef4-a951-0cac349d0f97
					  hl-color:: yellow
				- These laws of thought were supposed to govern the operation of the mind; their study initiated the ﬁeld called **logic**.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: green
				  id:: 67c26af5-3a3f-4b10-94d8-fbd0fcb9f563
			- Logicians in the 19th century developed a precise notation for statements about objects in the world and the relations among them. (Contrast this with ordinary arithmetic notation, which provides only for statements about numbers.)
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: blue
			  id:: 67c26b29-0618-49f2-ae3f-03b41b27b506
			  collapsed:: true
				- By 1965, programs could, in principle, solve any solvable problem described in logical notation.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c26b63-f99e-4e63-b36d-e3c6d549b801
			- The so-called **logicist** tradition within artiﬁcial intelligence hopes to build on such programs to create intelligent systems.
			  hl-stamp:: 1740794738709
			  hl-page:: 3
			  ls-type:: annotation
			  id:: 67c26b70-9cd4-4d35-9f50-e20937dcf2ad
			  hl-color:: green
			- Logic as conventionally understood requires knowledge of the world that is *certain*—a condition that, in reality, is seldom achieved.
			  hl-page:: 3
			  ls-type:: annotation
			  id:: 67c26b95-0de2-4224-9103-cb708e02cf02
			  hl-color:: blue
			  collapsed:: true
				- We simply don’t know the rules of, say, politics or warfare in the same way that we know the rules of chess or arithmetic.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c26bcd-e776-4650-901d-b8def33d9637
			- The theory of **probability** ﬁlls this gap, allowing rigorous reasoning with uncertain information.
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: green
			  id:: 67c26bdb-b644-44dd-abf9-44a33075135e
			  collapsed:: true
				- In principle, it allows the construction of a comprehensive model of rational thought, leading from raw perceptual information to an understanding of how the world works to predictions about the future.
				  ls-type:: annotation
				  hl-page:: 3
				  hl-color:: yellow
				  id:: 67c26d4a-7032-49ab-a4be-c5b9a3ea6839
			- What it does not do, is generate intelligent *behavior*. For that, we need a theory of rational action. Rational thought, by itself, is not enough.
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: blue
			  id:: 67c26d68-947b-412d-862a-330144043dfb
			  hl-stamp:: 1740795249341
		- 1.1.4 Acting rationally: The rational agent approach
		  ls-type:: annotation
		  hl-page:: 3
		  hl-color:: red
		  id:: 67c26d84-25e1-46f6-9e0c-3f1b013544fb
		  collapsed:: true
			- An **agent** is just something that acts (agent comes from the Latin agere, to do).
			  ls-type:: annotation
			  hl-page:: 3
			  hl-color:: green
			  id:: 67c26db2-377e-4f0c-a356-4b8210946856
			  collapsed:: true
				- Of course, all computer programs do something, but computer agents are expected to do more: operate autonomously, perceive their environment, persist over a prolonged time period, adapt to change, and create and pursue goals.
				  hl-page:: 4
				  ls-type:: annotation
				  id:: 67c26dd3-465e-4abf-88fa-c1e516ee984c
				  hl-color:: yellow
			- A **rational agent** is one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome.
			  hl-page:: 4
			  ls-type:: annotation
			  id:: 67c26de3-4928-49d4-b8d0-4cef1f5da99a
			  hl-color:: green
			- In the “laws of thought” approach to AI, the emphasis was on correct inferences.
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c26e27-c78d-409f-9b84-7718655ed78e
			  collapsed:: true
				- Making correct inferences is sometimes *part* of being a rational agent, because one way to act rationally is to deduce that a given action is best and then to act on that conclusion.
				  hl-page:: 4
				  ls-type:: annotation
				  id:: 67c279f5-562e-4b0f-821d-dc50ca572dd9
				  hl-color:: yellow
				- On the other hand, there are ways of acting rationally that cannot be said to involve inference. For example, recoiling from a hot stove is a reﬂex action that is usually more successful than a slower action taken after careful deliberation.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27a1c-773d-4333-ab58-5eddb23b5746
			- All the skills needed for the Turing test also allow an agent to act rationally.
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c27a3a-531f-4e50-9f8a-d52b61552a5e
			  collapsed:: true
				- Knowledge representation and reasoning enable agents to reach good decisions.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27a8e-7097-4d7c-8bf9-aaa1c6db3492
				- We need to be able to generate comprehensible sentences in natural language to get by in a complex society.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27a9a-be71-43d8-bd66-6ffc66ac5863
				- We need learning not only for erudition, but also because it improves our ability to generate effective behavior, especially in circumstances that are new.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27aa6-a46c-445a-b96b-fb445310f851
			- The rational-agent approach to AI has two advantages over the other approaches.
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c27aca-1ff2-48d2-ac1f-8e46f9b2f324
			  collapsed:: true
				- **First**, it is more general than the “laws of thought” approach because correct inference is just one of several possible mechanisms for achieving rationality.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27aeb-8a17-4102-88ee-b4f46f7b5375
				- Second, it is more amenable to scientiﬁc development. The standard of rationality is mathematically well deﬁned and completely general.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27b14-242b-4308-b116-57f8e215299c
					- ==_However it does create duplicitous answers that lack a cohesive outcome, it is therefore fractuous. This lack of directionality and discipline towards a perceived goal, reduces certainty of action that is core to having agency. A rational agent is by definition, not an agent, but constructs the environment of potentiality. The agent must collapse the possible into the certainty of outcome based on the desirable objective. Agent as defined here exposes the agent of Chaos as it fails to act and therefore fails to exclude an infinitely large scope of undesirable outcome._==
				- We can often work back from this speciﬁcation to derive agent designs that provably achieve it—something that is largely impossible if the goal is to imitate human behavior or thought processes.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c27bd6-9bc3-42b1-8330-9b5d45e3dbad
			- For these reasons, the rational-agent approach to AI has prevailed throughout most of the ﬁeld’s history.
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c28e06-1f8a-4e61-b266-fdd43e6b4402
			  collapsed:: true
				- In the early decades, rational agents were built on logical foundations and formed deﬁnite plans to achieve speciﬁc goals.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c28e35-bfa2-48ab-90ee-f3a9476d1c91
				- Later, methods based on probability theory and machine learning allowed the creation of agents that could make decisions under uncertainty to attain the best expected outcome.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c28e46-3f56-4941-b271-3dbfe4889f10
				- __In a nutshell, AI has focused on the study and construction of agents that *do the right thing*__. What counts as the right thing is deﬁned by the objective that we provide to the agent.
				  hl-page:: 4
				  ls-type:: annotation
				  id:: 67c28e54-6a53-411d-a139-9a9fceb9d641
				  hl-color:: yellow
				- This general paradigm is so pervasive that we might call it the **standard model.** It prevails not only in AI, but also in control theory, where a controller minimizes a cost function; in operations research, where a policy maximizes a sum of rewards; in statistics, where a decision rule minimizes a loss function; and in economics, where a decision maker maximizes utility or some measure of social welfare.
				  hl-page:: 4
				  ls-type:: annotation
				  id:: 67c28ef0-5048-4f82-981d-32729c61d73b
				  hl-color:: yellow
			- We need to make one important reﬁnement to the standard model to account for the fact that perfect rationality—always taking the exactly optimal action—is not feasible in complex environments. The computational demands are just too high. 
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c2f3a2-0a0e-45d1-bef1-0e48d9ec08a9
			- Chapters 6 and 16 deal with the issue of **limited rationality**—acting appropriately when there is not enough time to do all the computations one might like. However, perfect rationality often remains a good starting point for theoretical analysis.
			  hl-stamp:: 1740829625338
			  hl-page:: 4
			  ls-type:: annotation
			  id:: 67c2f3b5-c33a-448b-8a03-43881650d963
			  hl-color:: green
		- 1.1.5 Beneﬁcial machines
		  ls-type:: annotation
		  hl-page:: 4
		  hl-color:: red
		  id:: 67c2f3df-228a-4430-927f-661b676c4437
		  collapsed:: true
			- The standard model has been a useful guide for AI research since its inception, but it is probably not the right model in the long run. 
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c2f3f0-6e05-422c-ae7e-081df0c5157a
			  collapsed:: true
				- The reason is that the standard model assumes that we will supply a fully speciﬁed objective to the machine.
				  ls-type:: annotation
				  hl-page:: 4
				  hl-color:: yellow
				  id:: 67c2f3f6-e55e-412e-9943-a0b0e49a7c0f
			- For an artiﬁcially deﬁned task such as chess or shortest-path computation, the task comes with an objective built in—so the standard model is applicable
			  ls-type:: annotation
			  hl-page:: 4
			  hl-color:: blue
			  id:: 67c2f40b-f0a5-4783-adec-2bcd464b565c
			  collapsed:: true
				- As we move into the real world, however, it becomes more and more difﬁcult to specify the objective completely and correctly.
				  hl-page:: 4
				  ls-type:: annotation
				  id:: 67c2f420-23fd-40f5-9574-3f44f5eafa80
				  hl-color:: yellow
				- For example, in designing a self-driving car, one might think that the objective is to reach the destination safely. But driving along any road incurs a risk of injury due to other errant drivers, equipment failure, and so on; thus, a strict goal of safety requires staying in the garage.
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b2c5-1c34-4615-a695-c454fe0c712b
				- There is a tradeoff between making progress towards the destination and incurring a risk of injury. How should this tradeoff be made? Furthermore, to what extent can we allow the car to take actions that would annoy other drivers? How much should the car moderate its acceleration, steering, and braking to avoid shaking up the passenger?
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b301-207e-4b81-bc6f-3d85be2e1e77
				- These kinds of questions are difﬁcult to answer a priori. They are particularly problematic in the general area of human–robot interaction, of which the self-driving car is one example.
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b309-e960-422f-a374-018af5fbd194
			- The problem of achieving agreement between our true preferences and the objective we put into the machine is called the:
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: blue
			  id:: 67c3b31c-f086-450b-9575-56b4f3095f1d
			- **value alignment problem** - the values or objectives put into the machine must be aligned with those of the human
			  hl-page:: 5
			  ls-type:: annotation
			  id:: 67c3b33c-462f-4a4f-9e31-c874165f47e8
			  hl-color:: green
			  collapsed:: true
				- If we are developing an AI system in the lab or in a simulator—as has been the case for most of the ﬁeld’s history—there is an easyﬁx for an incorrectly speciﬁed objective: reset the system, ﬁx the objective, and try again.
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b38a-5301-4a14-a970-6de39e2b6271
				- As the ﬁeld progresses towards increasingly capable intelligent systems that are deployed in the real world, this approach is no longer viable. A system deployed with an incorrect objective will have negative consequences. Moreover, the more intelligent the system, the more negative the consequences.
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b3a7-a327-4889-871e-f7847144a14e
			- Returning to the apparently unproblematic example of chess, consider what happens if the machine is intelligent enough to reason and act beyond the conﬁnes of the chessboard.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: blue
			  id:: 67c3b3bf-8abc-458b-9839-0713f1c2a080
			  collapsed:: true
				- In that case, it might attempt to increase its chances of winning by such ruses as hypnotizing or blackmailing its opponent or bribing the audience to make rustling noises during its opponent’s thinking time.[^3]
				  hl-page:: 5
				  ls-type:: annotation
				  id:: 67c3b3ce-ffe7-4e97-bd27-d89e301d967e
				  hl-color:: yellow
				  collapsed:: true
					- hl-page:: 5
					  ls-type:: annotation
					  id:: 67c3b3da-d4da-4fff-8cd8-a566c775d33a
					  hl-color:: purple
					  [^3]:In one of the ﬁrst books on chess, Ruy Lopez (1561) wrote, “Always place the board so the sun is in your opponent’s eyes.”
				- It might also attempt to hijack additional computing power for itself. *These behaviors are not “unintelligent” or “insane”; they are a logical consequence of deﬁning winning as the sole objective for the machine*.
				  hl-page:: 5
				  ls-type:: annotation
				  id:: 67c3b414-dc5f-4bce-8460-d52aab715d71
				  hl-color:: yellow
			- It is impossible to anticipate all the ways in which a machine pursuing a ﬁxed objective might misbehave. There is good reason, then, to think that the standard model is inadequate.
			  hl-page:: 5
			  ls-type:: annotation
			  id:: 67c3b587-f8c0-478a-989d-22064c5087af
			  hl-color:: blue
			  collapsed:: true
				- We don’t want machines that are intelligent in the sense of pursuing *their* objectives; we want them to pursue *our* objectives. If we cannot transfer those objectives perfectly to the machine, then we need a new formulation—one in which the machine is pursuing our objectives, but is necessarily *uncertain* as to what they are.
				  hl-page:: 5
				  ls-type:: annotation
				  id:: 67c3b5c0-362f-454f-a548-5ae0abc82401
				  hl-color:: yellow
				- When a machine knows that it doesn’t know the complete objective, it has an incentive to act cautiously, to ask permission, to learn more about our preferences through observation, and to defer to human control.
				  ls-type:: annotation
				  hl-page:: 5
				  hl-color:: yellow
				  id:: 67c3b624-03d2-4c5f-a824-072afd8d503f
			- Ultimately, we want agents that are **provably beneﬁcial** to humans. We will return to this topic in Section 1.5.
			  ls-type:: annotation
			  hl-page:: 5
			  hl-color:: green
			  id:: 67c3b631-2d83-405e-993f-a37dfaf8713b
			  hl-stamp:: 1740879411869
- 1.2 The Foundations of Artiﬁcial Intelligence
  ls-type:: annotation
  hl-page:: 5
  hl-color:: red
  id:: 67c3b65f-aee2-4c0e-87d3-1e55824895bf
	- In this section, we provide a brief history of the disciplines that contributed ideas, viewpoints, and techniques to AI.
	  ls-type:: annotation
	  hl-page:: 5
	  hl-color:: blue
	  id:: 67c3b678-030c-4a4f-99b3-f82557c3e90b
	  collapsed:: true
		- Like any history, this one concentrates on a small number of people, events, and ideas and ignores others that also were important.
		  ls-type:: annotation
		  hl-page:: 5
		  hl-color:: yellow
		  id:: 67c3b693-a559-4ff0-8d08-c137059ed341
		- We organize the history around a series of questions. We certainly would not wish to give the impression that these questions are the only ones the disciplines address or that the disciplines have all been working toward AI as their ultimate fruition.
		  ls-type:: annotation
		  hl-page:: 5
		  hl-color:: yellow
		  id:: 67c3b6b3-19f7-4d4d-afa1-0d49e8fec927
- 1.2.1 Philosophy
  ls-type:: annotation
  hl-page:: 6
  hl-color:: red
  id:: 67c3b6c1-3fdd-4671-a8ca-8cd2f9e2a1b6
	- [[Aristotle]] (384–322 BCE) was the ﬁrst to formulate a precise set of laws governing the rational part of the mind.
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: blue
	  id:: 67c3b6d5-e144-4e8d-9b9f-309bdc11f62b
	  collapsed:: true
		- He developed an informal system of syllogisms for proper reasoning, which in principle allowed one to generate conclusions mechanically, given initial premises.
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: yellow
		  id:: 67c3b754-4918-478f-bc97-69501ef15ff6
	- [[Ramon Llull]] (c. 1232–1315) devised a system of reasoning published as *Ars Magna* or *The Great Art* (1305). Llull tried to implement his system using an actual mechanical device: a set of paper wheels that could be rotated into different permutations.
	  hl-page:: 6
	  ls-type:: annotation
	  id:: 67c3b76f-6850-43be-ad0b-675e3f590861
	  hl-color:: blue
	- Around 1500, [[Leonardo da Vinci]] (1452–1519) designed but did not build a mechanical calculator; recent reconstructions have shown the design to be functional
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: blue
	  id:: 67c3b7e2-91f1-4ffa-8b88-186776edb478
	- The ﬁrst known calculating machine was constructed around 1623 by the German scientist [[Wilhelm Schickard]] (1592–1635).
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: blue
	  id:: 67c3b7ff-185f-4fbb-afd0-451181dbf59e
	  hl-stamp:: 1740880466711
	- [[Blaise Pascal]] (1623–1662) built the Pascaline in 1642 and wrote that it “produces effects which appear nearer to thought than all the actions of animals.
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: blue
	  id:: 67c3b81a-92ff-4532-a94c-8dae08e89e36
	  hl-stamp:: 1740880485715
	- [[Gottfried Wilhelm Leibniz]] (1646–1716) built a mechanical device intended to carry out operations on concepts rather than numbers, but its scope was rather limited
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: blue
	  id:: 67c3b840-f7bc-4801-ad95-5707edb0b1b4
	  hl-stamp:: 1740880491153
	- In his 1651 book *Leviathan*, [[Thomas Hobbes]] (1588–1679) suggested the idea of a thinking machine, an “artiﬁcial animal” in his words, arguing “For what is the heart but a spring; and the nerves, but so many strings; and the joints, but so many wheels.” He also suggested that reasoning was like numerical computation: “For ‘reason’ . . . is nothing but ‘reckoning,’ that is adding and subtracting.”
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: blue
	  id:: 67c3b888-7a47-4c37-8261-c93773965cbe
	  hl-stamp:: 1740880495585
	- It’s one thing to say that the mind operates, at least in part, according to logical or numerical rules, and to build physical systems that emulate some of those rules. It’s another to say that the mind itself is such a physical system.
	  hl-page:: 6
	  ls-type:: annotation
	  id:: 67c3b8c7-19b9-4abc-8114-0aca63b2eb28
	  hl-color:: blue
	  hl-stamp:: 1740880089028
	- [[René Descartes]] (1596–1650) gave the ﬁrst clear discussion of the distinction between mind and matter. He noted that a purely physical conception of the mind seems to leave little room for free will.
	  hl-page:: 6
	  ls-type:: annotation
	  id:: 67c3b8fa-ffd4-48d1-aef2-4f8faf8965f4
	  hl-color:: blue
	  hl-stamp:: 1740880460455
	  collapsed:: true
		- If the mind is governed entirely by physical laws, then it has no more free will than a rock “deciding” to fall downward.
		  ls-type:: annotation
		  hl-page:: 6
		  hl-color:: yellow
		  id:: 67c3ba26-f8da-499a-b44a-6894bd5a6d51
	- Descartes was a proponent of **dualism**. He held that there is a part of the human mind (orDualism soul or spirit) that is outside of nature, exempt from physical laws. Animals, on the other hand, did not possess this dual quality; they could be treated as machines.
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: green
	  id:: 67c3ba3c-4618-4150-b496-6be028cd638c
	- An alternative to dualism is **materialism**, which holds that the brain’s operation according to the laws of physics constitutes the mind. Free will is simply the way that the perception of available choices appears to the choosing entity.
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: green
	  id:: 67c3bb18-2f72-46d0-adf2-39a407753929
	  hl-stamp:: 1740880679166
	- The terms **physicalism** and **naturalism** are also used to describe this view that stands in contrast to the supernatural.
	  hl-page:: 6
	  ls-type:: annotation
	  id:: 67c3bb2f-5f4c-4060-9711-45fa920faaa3
	  hl-color:: green
	- Given a physical mind that manipulates knowledge, the next problem is to establish the source of knowledge.
	  ls-type:: annotation
	  hl-page:: 6
	  hl-color:: blue
	  id:: 67c3bb52-a6e1-49e9-ac87-d198900e6c7c
	- The **empiricism** movement, starting with [[Francis Bacon]]’s (1561–1626) *Novum Organum*,[^4] is characterized by a dictum of [[John Locke]] (1632–1704): “Nothing is in the understanding, which was not ﬁrst in the senses.”
	  hl-page:: 6
	  ls-type:: annotation
	  id:: 67c3bb60-ea56-45c5-b2af-5d2109b271ab
	  hl-color:: green
	  collapsed:: true
		- hl-page:: 6
		  ls-type:: annotation
		  id:: 67c3bbb0-0b43-4cbb-ad99-3f1a90c4c582
		  hl-color:: purple
		  [^4]:The *Novum Organum* is an update of Aristotle’s *Organon*, or instrument of thought.
	- [[David Hume]]’s (1711–1776) *A Treatise of Human Nature* (Hume, 1739) proposed what is now known as the principle of **induction**: that general rules are acquired by exposure toInduction repeated associations between their elements.
	  hl-page:: 6
	  ls-type:: annotation
	  id:: 67c3bfa8-92f4-4970-b441-d028aa7cc719
	  hl-color:: green
	- Building on the work of [[Ludwig Wittgenstein]] (1889–1951) and [[Bertrand Russell]] (1872–1970), the famous [[Vienna Circle]] (Sigmund, 2017), a group of philosophers and mathematicians meeting in Vienna in the 1920s and 1930s, developed the doctrine of **logical positivism**.
	  ls-type:: annotation
	  hl-page:: 7
	  hl-color:: green
	  id:: 67c3bfef-8197-4675-a928-65b2ed904a0d
	- This doctrine holds that all knowledge can be characterized by logical theories connected, ultimately, to **observation sentences** that correspond to sensory inputs; thus logical positivism combines rationalism and empiricism.
	  hl-page:: 7
	  ls-type:: annotation
	  id:: 67c3c02b-33a0-4b0c-87ee-b76cbe9beafb
	  hl-color:: green
	  hl-stamp:: 1740882066321
	- The **conﬁrmation theory** of [[Rudolf Carnap]] (1891–1970) and [[Carl Hempel]] (1905–1997) attempted to analyze the acquisition of knowledge from experience by quantifying the degree of belief that should be assigned to logical sentences based on their connection to observations that conﬁrm or disconﬁrm them.
	  hl-page:: 7
	  ls-type:: annotation
	  id:: 67c3c0a6-147a-4b9e-8596-46f1c79332c0
	  hl-color:: green
	  collapsed:: true
		- Carnap’s book *The Logical Structure of the World* (1928) was perhaps the ﬁrst theory of mind as a computational process.
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: yellow
		  id:: 67c3c0c6-6d7f-40e2-a21f-24a686c4542a
	- The ﬁnal element in the philosophical picture of the mind is the connection between knowledge and action.
	  ls-type:: annotation
	  hl-page:: 7
	  hl-color:: blue
	  id:: 67c3c0e4-4b01-4887-a23d-502d7a781551
	  collapsed:: true
		- This question is vital to AI because intelligence requires action as well as reasoning. Moreover, only by understanding how actions are justiﬁed can we understand how to build an agent whose actions are justiﬁable (or rational).
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: yellow
		  id:: 67c3c0ee-3acd-4afe-bd23-94a06eb9cd77
	- Aristotle argued (in *De Motu Animalium*) that actions are justiﬁed by a logical connection between goals and knowledge of the action’s outcome:
	  ls-type:: annotation
	  hl-page:: 7
	  hl-color:: blue
	  id:: 67c3c106-0527-47f2-baf3-15e7b4d42b63
	  collapsed:: true
		- ls-type:: annotation
		  hl-page:: 7
		  hl-color:: yellow
		  id:: 67c3c27c-0022-40c1-87bc-d9359f6d0edf
		  >But how does it happen that thinking is sometimes accompanied by action and sometimes not, sometimes by motion, and sometimes not? It looks as if almost the same thing happens as in the case of reasoning and making inferences about unchanging objects. But in that case the end is a speculative proposition . . . whereas here the conclusion which results from the two premises is an action. . . . I need covering; a cloak is a covering. I need a cloak. What I need, I have to make; I need a cloak. I have to make a cloak. And the conclusion, the “I have to make a cloak,” is an action.
	- In the *Nicomachean Ethics* (Book III. 3, 1112b), Aristotle further elaborates on this topic, suggesting an algorithm:
	  ls-type:: annotation
	  hl-page:: 7
	  hl-color:: blue
	  id:: 67c3c2c3-19e9-4369-bb6e-dda74e78b840
	  collapsed:: true
		- hl-page:: 7
		  ls-type:: annotation
		  id:: 67c3c2d6-da7f-4993-86de-6a87416a6ccf
		  hl-color:: yellow
		  >We deliberate not about ends, but about means. For a doctor does not deliberate whether he shall heal, nor an orator whether he shall persuade, . . . They assume the end and consider how and by what means it is attained, and if it seems easily and best produced thereby; while if it is achieved by one means only they consider *how* it will be achieved by this and by what means *this* will be achieved, till they come to the ﬁrst cause, . . . and what is last in the order of analysis seems to be ﬁrst in the order of becoming. And if we come on an impossibility, we give up the search, e.g., if we need money and this cannot be got; but if a thing appears possible we try to do it.
	- [[Aristotle]]’s algorithm was implemented 2300 years later by Newell and Simon in their **General Problem Solver** program.
	  ls-type:: annotation
	  hl-page:: 7
	  hl-color:: green
	  id:: 67c3c5f6-8ef5-4593-9b8e-b3f747729146
	  collapsed:: true
		- We would now call it a greedy regression planning system(see Chapter 11). Methods based on logical planning to achieve deﬁnite goals dominated theﬁrst few decades of theoretical research in AI.
		  ls-type:: annotation
		  hl-page:: 7
		  hl-color:: yellow
		  id:: 67c3c61f-10bf-4dbc-82aa-179207267a88
	- Thinking purely in terms of actions achieving goals is often useful but sometimes inapplicable.
	  ls-type:: annotation
	  hl-page:: 7
	  hl-color:: blue
	  id:: 67c3db63-7d27-49b3-a20f-83907722315d
	  collapsed:: true
		- For example, if there are several different ways to achieve a goal, there needs to be some way to choose among them. More importantly, it may not be possible to achieve a goal with certainty, but some action must still be taken. How then should one decide?
		  hl-page:: 7
		  ls-type:: annotation
		  id:: 67c3dbdd-f24b-4150-950a-dd8840ce47a4
		  hl-color:: yellow
- [[Antoine Arnauld]] (1662), analyzing the notion of rational decisions in gambling, proposed a quantitative formula for maximizing the expected monetary value of the outcome
  ls-type:: annotation
  hl-page:: 7
  hl-color:: blue
  id:: 67c3dc5b-600c-40db-803b-f54174900438
- Later, [[Daniel Bernoulli]] (1738) introduced the more general notion of utility to capture the internal, subjective value
  ls-type:: annotation
  hl-page:: 7
  hl-color:: green
  id:: 67c3dc72-5201-4c31-9056-d08556979214